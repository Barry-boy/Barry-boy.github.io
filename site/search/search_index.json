{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"Storage/rook-ceph/","text":"rook-ceph\u7b80\u4ecb\u548c\u90e8\u7f72 \u00b6 rook-ceph\u7b80\u4ecb \u00b6 \u5f00\u6e90\u7684\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\uff0c\u652f\u6301\u5bf9\u8c61\u5b58\u50a8\uff0c\u5757\u8bbe\u5907\uff0c\u6587\u4ef6\u7cfb\u7edf \u5757\u5b58\u50a8 CephFs \u5bf9\u8c61\u5b58\u50a8 ceph \u7684\u7248\u672c\u5386\u53f2 \u00b6 x.0.z - \u5f00\u53d1\u7248 x.1.z - \u5019\u9009\u7248 x.2.z - \u7a33\u5b9a\uff0c\u4fee\u6b63\u7248 ceph\u96c6\u7fa4\u89d2\u8272\u5b9a\u4e49 \u00b6 \u6ce8\u610f ceph\u96c6\u7fa4\u7684osd\u8282\u70b9\u4e00\u822c\u4fdd\u8bc1>=3\u4e2a\uff0c\u6765\u4fdd\u8bc1\u6570\u636e\u7684\u9ad8\u53ef\u7528\u6027\u3002 mon : ceph \u76d1\u89c6\u5668,\u5728\u4e00\u4e2a\u4e3b\u673a\u4e0a\u8fd0\u884c\u7684\u4e00\u4e2a\u5b88\u62a4\u8fdb\u7a0b\uff0c\u7528\u4e8e\u7ef4\u62a4\u96c6\u7fa4\u72b6\u6001\u6620\u5c04\u5173\u7cfb mgr : \u8d1f\u8d23\u8ddf\u8e2a\u8fd0\u884c\u65f6\u6307\u6807\u548cceph\u96c6\u7fa4\u7684\u5f53\u524d\u72b6\u6001 osd : \u78c1\u76d8\uff08\u771f\u6b63\u5b58\u50a8\u6570\u636e\u7684\u5730\u65b9\uff09 ceph \u9762\u8bd5\u9898 ceph rook-ceph\u90e8\u7f72 \u00b6 \u73af\u5883\u8981\u6c42 \u4e00\u4e2ak8s\u96c6\u7fa4\uff0cnode\u8282\u70b9\u6700\u5c11\u4e09\u4e2a\u8282\u70b9 mon: 8C 8G/200G 16C 16g/32-200G \u666e\u901a\u6d4b\u8bd5\u90e8\u7f72\uff1a \u00b6 \u90e8\u7f72crds\uff0ccommon\uff0coperator \u00b6 [ucloud] root@master0:~# git clone --single-branch --branch v1.5.5 https://github.com/rook/rook.git cd rook/cluster/examples/kubernetes/ceph kubectl create -f crds.yaml -f common.yaml -f operator.yaml kubectl create -f cluster.yaml \u955c\u50cf\u5217\u8868\uff1a \u00b6 # ROOK_CSI_CEPH_IMAGE: \"quay.io/cephcsi/cephcsi:v3.4.0\" # ROOK_CSI_REGISTRAR_IMAGE: \"k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\" # ROOK_CSI_RESIZER_IMAGE: \"k8s.gcr.io/sig-storage/csi-resizer:v1.3.0\" # ROOK_CSI_PROVISIONER_IMAGE: \"k8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\" # ROOK_CSI_SNAPSHOTTER_IMAGE: \"k8s.gcr.io/sig-storage/csi-snapshotter:v4.2.0\" # ROOK_CSI_ATTACHER_IMAGE: \"k8s.gcr.io/sig-storage/csi-attacher:v3.3.0\" CSI\u83b7\u53d6\u955c\u50cf\u811a\u672c\uff1a \u00b6 [ ucloud ] root@node0:/home/lixie# cat <<EOF>> image-sci.sh #!/bin/bash image_list=' csi-node-driver-registrar:v2.0.1 csi-attacher:v3.0.0 csi-snapshotter:v3.0.0 csi-resizer:v1.0.0 csi-provisioner:v2.0.0 ' aliyuncs=\"registry.aliyuncs.com/it00021hot\" google_gcr=\"k8s.gcr.io/sig-storage\" for image in $image_list do echo $image docker pull ${aliyuncs}/${image} docker tag ${aliyuncs}/${image} ${google_gcr}/${image} docker rm ${aliyuncs}/${image} #echo \"${aliyuncs}/${image} ${google_gcr}/${image} downloaded.\" done EOF \u5b9a\u5236\u5316\u90e8\u7f72\uff1a \u00b6 \u5b9a\u5236mon\u8c03\u5ea6\u53c2\u6570 \u00b6 \u80cc\u666f \u2f63\u4ea7\u73af\u5883\u6709\u2f00\u4e9b\u4e13\u2ed4\u7684\u8282\u70b9\u2f64\u4e8emon\u3001mgr\uff0c\u5b58\u50a8\u8282\u70b9\u8282\u70b9\u4f7f\u2f64\u5355\u72ec\u7684\u8282\u70b9\u627f\u62c5,\u5229\u2f64\u8c03\u5ea6\u673a\u5236\u5b9e \u73b0 placement : mon : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-mon operator : In values : - enabled #\u8bbe\u7f6e\u78c1\u76d8\u7684\u53c2\u6570\uff0c\u8c03\u6574\u4e3afalse\uff0c\u2f45\u4fbf\u540e\u2faf\u5b9a\u5236 214 useAllNodes : false 215 useAllDevices : false \u5206\u522b\u7ed9\u8282\u70b9\u6253\u4e0a\u6807\u7b7e [ucloud] root@master0:~# kubectl label node node0 ceph-mon=enabled node/node0 labeled [ucloud] root@master0:~# kubectl label node node1 ceph-mon=enabled node/node1 labeled [ucloud] root@master0:~# kubectl label node node2 ceph-mon=enabled node/node2 labeled \u83b7\u53d6\u955c\u50cf\u811a\u672c $ cat image-rook-ceph-sci-v1.7.11.sh #!/bin/bash image_list=' csi-node-driver-registrar:v2.0.1 csi-attacher:v3.0.0 csi-snapshotter:v3.0.0 csi-resizer:v1.0.0 csi-provisioner:v2.0.0 ' aliyuncs=\"registry.aliyuncs.com/it00021hot\" google_gcr=\"k8s.gcr.io/sig-storage\" for image in $image_list do echo $image docker pull ${aliyuncs}/${image} docker tag ${aliyuncs}/${image} ${google_gcr}/${image} #docker rm ${aliyuncs}/${image} #echo \"${aliyuncs}/${image} ${google_gcr}/${image} downloaded.\" done EOF \u5b9a\u5236mgr\u8c03\u5ea6\u53c2\u6570 \u00b6 \u6e29\u99a8\u63d0\u793a \u4fee\u6539mgr\u7684\u8c03\u5ea6\u53c2\u6570,\u4fee\u6539\u5b8c\u4e4b\u540e\u91cd\u65b0apply cluster.yaml\u914d\u7f6e\u4f7f\u5176\u52a0\u8f7d\u5230\u96c6\u7fa4\u4e2d mgr : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-mgr operator : In values : - enabled \u6b64\u65f6\u8c03\u5ea6\u4f1a\u5931\u8d25\uff0c\u7ed9node-1\u548cnode-2\u6253\u4e0a ceph-mgr=enabled \u7684\u6807\u7b7e $ kubectl label nodes node0 ceph-mgr=enabled node/node0 labeled $ kubectl label nodes node1 ceph-mgr=enabled node/node1 labeled \u5b9a\u5236msd\u8c03\u5ea6\u53c2\u6570 \u00b6 \u8bbe\u7f6eosd\u7684\u8c03\u5ea6\u53c2\u6570 osd : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-osd operator : In values : - enabled \u5b9a\u5236osd\u7684\u78c1\u76d8\u53c2\u6570 nodes : - name : \"node0\" devices : # specific devices to use for storage can be specified for each node - name : \"vdb\" - name : \"node1\" devices : # specific devices to use for storage can be specified for each node - name : \"vdc\" toolbox\u5ba2\u6237\u7aef \u00b6 apply\u4ee5\u4e0b\u4e2d\u4e24\u4e2a\u6587\u4ef6\u7684\u4e00\u4e2a\u5c31\u53ef\u4ee5\uff0c\u4e00\u822c\u9009\u62e9toolbox.yaml $ ll tool* -rw-r--r-- 1 beiyiwangdejiyi staff 1.7K 7 19 17:26 toolbox-job.yaml # \u4e00\u6b21\u6027\u4efb\u52a1 -rw-r--r-- 1 beiyiwangdejiyi staff 1.4K 7 19 17:26 toolbox.yaml kubectl apply -f toolbox.yaml k8s\u8bbf\u95eeceph \u00b6 centos\u7cfb\u7edf\uff1a 1. \u914d\u7f6eCeph yum\u6e90 \u00b6 [root@node-1 ~]# cat /etc/yum.repos.d/ceph.repo [ceph] name=ceph baseurl=https://mirrors.aliyun.com/ceph/rpm-octopus/el8/x86_64/ enabled=1 gpgcheck=0 2.\u5b89\u88c5ceph-common \u00b6 [root@node-1 ~]# yum -y install ceph-common 3. \u521b\u5efaceph\u914d\u7f6e\u6587\u4ef6 \u00b6 [root@rook-ceph-tools-65c94d77bb-b9b2h /]# cat /etc/ceph/ceph.conf # \u67e5\u770b\u4e4b\u540e\u5bbf\u4e3b\u673a\u521b\u5efa [global] mon_host = 10.43.248.216:6789,10.43.174.200:6789,10.43.9.21:6789 [client.admin] keyring = /etc/ceph/keyring [root@rook-ceph-tools-65c94d77bb-b9b2h /]# cat /etc/ceph/keyring # \u67e5\u770b\u4e4b\u540e\u5bbf\u4e3b\u673a\u521b\u5efa [client.admin] key = AQCRS+NijUeiIxAAhFtv6je2FmMEAVHAJJqPwg== ubuntu\u7cfb\u7edf\uff1a apt install ceph-common \u8bbf\u95eeRBD\u5757\u5b58\u50a8 \u00b6 1.\u521b\u5efa\u4e00\u4e2apool \u00b6 [ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # ceph osd pool create rook 16 16 pool 'rook' created [root@rook-ceph-tools-65c94d77bb-xg6xs /]# ceph osd lspools # \u67e5\u770bpools 1 device_health_metrics 2 replicapool 3 rook 2. \u5728pool\u4e0a\u521b\u5efa\u5757\u8bbe\u5907 \u00b6 [ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # rbd create -p rook --image rook-rbd.img --size 10G [ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # rbd ls -p rook rook-rbd.img [root@rook-ceph-tools-65c94d77bb-xg6xs /]# rbd info rook/rook-rbd.img # \u67e5\u770b\u8be6\u7ec6\u4fe1\u606f rbd image 'rook-rbd.img' : size 10 GiB in 2560 objects order 22 (4 MiB objects) snapshot_count : 0 id : 50a7fcf85890 block_name_prefix : rbd_data.50a7fcf85890 format : 2 features : layering op_features : flags : create_timestamp : Fri Jul 29 05:40:05 2022 access_timestamp : Fri Jul 29 05:40:05 2022 modify_timestamp : Fri Jul 29 05:40:05 2022 3\u3001\u5ba2\u6237\u6302\u8f7dRBD\u5757 \u00b6 [ ucloud ] root@master0:/home/lixie# rbd map rook/rook-rbd.img /dev/rbd0 [ ucloud ] root@master0:/home/lixie# rbd showmapped id pool namespace image snap device 0 rook rook-rbd.img - /dev/rbd0 [ ucloud ] root@master0:/home/lixie# mkfs.xfs /dev/rbd0 meta-data = /dev/rbd1 isize = 512 agcount = 16 , agsize = 163840 blks = sectsz = 512 attr = 2 , projid32bit = 1 = crc = 1 finobt = 1 , sparse = 1 , rmapbt = 0 = reflink = 1 data = bsize = 4096 blocks = 2621440 , imaxpct = 25 = sunit = 16 swidth = 16 blks naming = version 2 bsize = 4096 ascii-ci = 0 , ftype = 1 log = internal log bsize = 4096 blocks = 2560 , version = 2 = sectsz = 512 sunit = 16 blks, lazy-count = 1 realtime = none extsz = 4096 blocks = 0 , rtextents = 0 \u95ee\u9898\u4e00\uff1a\u52a0\u8f7d rbd \u5185\u6838\u6a21\u5757\u5931\u8d25 [root@rook-ceph-tools-65c94d77bb-xg6xs /]# rbd map rook/rook-rbd.img modinfo: ERROR: Module alias rbd not found. modprobe: FATAL: Module rbd not found in directory /lib/modules/5.4.0-48-generic rbd: failed to load rbd kernel module (1) rbd: failed to set udev buffer size: (1) Operation not permitted rbd: sysfs write failed In some cases useful info is found in syslog - try \"dmesg | tail\". rbd: map failed: (2) No such file or directory \u89e3\u51b3\u65b9\u6cd5\uff1a [ucloud] root@node0:/home/lixie# modprobe rbd [ucloud] root@node0:/home/lixie# lsmod |grep rbd rbd 106496 0 libceph 327680 1 rbd \u95ee\u9898\u4e8c\uff1amap rdb [root@rook-ceph-tools-65c94d77bb-b9b2h /]# rbd map rook/rook-rbd.img rbd: failed to set udev buffer size: (1) Operation not permitted rbd: sysfs write failed In some cases useful info is found in syslog - try \"dmesg | tail\". \u89e3\u51b3\u65b9\u6cd5\uff1a \u5728\u5bbf\u4e3b\u673a\u4e0a\u6267\u884c\uff0c\u8be5\u547d\u4ee4\u3002 \u95ee\u9898\u4e09: \u5185\u6838\u6a21\u5757\u4e0d\u652f\u6301\u8fd9\u4e48\u591a\u7684\u7279\u6027 [dev] root@master0:/home/lixie# rbd map rook/rook-rbd1.img rbd: sysfs write failed RBD image feature set mismatch. You can disable features unsupported by the kernel with \"rbd feature disable rook/rook-rbd1.img object-map fast-diff deep-flatten\". In some cases useful info is found in syslog - try \"dmesg | tail\". rbd: map failed: (6) No such device or address \u89e3\u51b3\u65b9\u6cd5\uff1a rbd feature disable rook/rook-rbd1.img object-map fast-diff deep-flatten # \u6309\u7167\u4ed6\u7684\u63d0\u793a\uff0c\u5148\u7981\u6b62\u8fd9\u4e9b\u7279\u6027\u518dmap Dashbaard \u56fe\u5f62\u7ba1\u7406 \u00b6 \u6e29\u99a8\u63d0\u793a \u6ce8\u610f\u9700\u8981\u5c06\u4e3b\u673a\u66b4\u6f0f\u7aef\u53e3\u7684\u5b89\u5168\u7ec4\u6253\u5f00\uff0c\u5b89\u5168\u7ec4\u6253\u5f00 31926 \u7aef\u53e3 \u542f\u2f64\u4e4b\u540e\uff0c\u53ef\u4ee5\u770b\u5230rook-ceph-mgr-dashboard-external-http\u7684service\uff0c\u5176\u7c7b\u578b\u662fNodePort\uff0c /Users/beiyiwangdejiyi/k8s-data/rook-v1.6.11/cluster/examples/kubernetes/ceph k apply -f dashboard-external-http.yaml $ k get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE csi-cephfsplugin-metrics ClusterIP 10.97.7.142 <none> 8080/TCP,8081/TCP 579d csi-rbdplugin-metrics ClusterIP 10.97.0.194 <none> 8080/TCP,8081/TCP 579d rook-ceph-mgr ClusterIP 10.97.15.77 <none> 9283/TCP 579d rook-ceph-mgr-dashboard ClusterIP 10.97.4.98 <none> 7000/TCP 579d rook-ceph-mgr-dashboard-external-http NodePort 10.97.10.172 <none> 7000:31926/TCP 8m18s \u9ed8\u8ba4mgr\u521b\u5efa\u4e86\u2f00\u4e2aadmin\u7684\u2f64\u6237\uff0c\u5176\u5bc6\u7801\u5b58\u653e\u5728rook-ceph-dashboard-password\u7684secrets\u5bf9\u8c61\u4e2d\uff0c\u901a\u8fc7\u5982\u4e0b\u2f45\u5f0f\u53ef\u4ee5\u83b7\u53d6\u5230 kubectl get secrets -n rook-ceph rook-ceph-dashboard-password -oyaml apiVersion : v1 data : password : XTBndSx0iRxxxEN1xbE9Uxxxx2JQSSE= # \u91c7\u7528base64\u52a0\u5bc6 kind : Secret metadata : creationTimestamp : \"2020-12-16T18:01:16Z\" name : rook-ceph-dashboard-password namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"103972533\" uid : 7082d4ad-47bb-46e2-b439-624016cc5f81 type : kubernetes.io/rook base64 \u89e3\u5bc6 $ echo XTBndS0iREN1bE9UMGpQY2JQSSE= | base64 -d ]0gu-\"DCulOT0jPcbPI!% \u6d4b\u8bd5\u767b\u9646 URL: http://xxxxxxxxx:31926/ \u5e10\u53f7: admin \u5bc6\u7801: xxxxxxxxxx \u8fdb\u5165\u5c31\u53ef\u4ee5\u770b\u5230\u4e00\u4e0b\u754c\u9762 Dashboard \u76d1\u63a7ceph \u00b6 $ k get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE csi-cephfsplugin-metrics ClusterIP 10.97.7.142 <none> 8080/TCP,8081/TCP 580d csi-rbdplugin-metrics ClusterIP 10.97.0.194 <none> 8080/TCP,8081/TCP 580d rook-ceph-mgr ClusterIP 10.97.15.77 <none> 9283/TCP 580d # \u7ed9prometheus\u4f5c\u4e3a\u5ba2\u6237\u7aef\u4f7f\u7528\u7684 ...... \u90e8\u7f72Prometheus Operator \u00b6 kubectl apply -f https://raw.githubusercontent.com/coreos/prometheus-operator/v0.40.0/bundle.yaml \u786e\u8ba4prometheus-operator\u5904\u4e8erun\u72b6\u6001 $ k get pod prometheus-operator-7ccf6dfc8-d9dmm 1/1 Running 0 142 \u90e8\u7f72Prometheus Instances \u00b6 $ git clone --single-branch --branch v1.6.11 https://github.com/rook/rook.git cd rook/cluster/examples/kubernetes/ceph/monitoring \u521b\u5efa\u670d\u52a1\u76d1\u89c6\u5668\u4ee5\u53ca Prometheus \u670d\u52a1\u5668 pod \u548c\u670d\u52a1 kubectl create -f service-monitor.yaml kubectl create -f prometheus.yaml kubectl create -f prometheus-service.yaml \u672c\u5730\u6d4b\u8bd5\u8bbf\u95ee\uff1a $ k port-forward pod/prometheus-rook-prometheus-0 -n rook-ceph 9090 9090 \u8bbf\u95ee\uff1ahttp://localhost:9090/ grafana\u6d4b\u8bd5\u8bbf\u95ee\uff1a $ k port-forward pod/grafana-cc568dbd8-4nvlq -n infra 3000 80 \u8bbf\u95ee\uff1ahttp://localhost:3000/ \u5e10\u53f7\uff1aadmin \u5bc6\u7801\uff1axxxxxxxxxxx \u76d1\u63a7\u5c55\u677f Ceph - Cluster\uff1ahttps://grafana.com/grafana/dashboards/2842 Ceph - OSD \uff1a https://grafana.com/grafana/dashboards/5336 Ceph - Pools\uff1a https://grafana.com/grafana/dashboards/5342 \u5bf9\u8c61\u5b58\u50a8 \u00b6 \u90e8\u7f72RGW\u5bf9\u8c61\u5b58\u50a8 \u00b6 $ k apply -f object.yaml [ ucloud ] root@master0:~/.kube# kubectl get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE csi-rbdplugin-metrics ClusterIP 10 .43.40.164 <none> 8080 /TCP,8081/TCP 7d4h csi-cephfsplugin-metrics ClusterIP 10 .43.170.151 <none> 8080 /TCP,8081/TCP 7d4h rook-ceph-mon-a ClusterIP 10 .43.248.216 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mon-b ClusterIP 10 .43.174.200 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mon-c ClusterIP 10 .43.9.21 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mgr-dashboard ClusterIP 10 .43.193.31 <none> 8443 /TCP 7d4h rook-ceph-mgr ClusterIP 10 .43.114.15 <none> 9283 /TCP 7d4h wordpress-mysql ClusterIP None <none> 3306 /TCP 7d3h rook-prometheus NodePort 10 .43.128.1 <none> 9090 :30900/TCP 3d prometheus-operated ClusterIP None <none> 9090 /TCP 3d rook-ceph-rgw-my-store ClusterIP 10 .43.73.235 <none> 80 /TCP 18m [ ucloud ] root@master0:~/.kube# curl http://10.43.73.235 <?xml version = \"1.0\" encoding = \"UTF-8\" ?><ListAllMyBucketsResult xmlns = \"http://s3.amazonaws.com/doc/2006-03-01/\" ><Owner><ID>anonymous</ID><DisplayName></DisplayName></Owner><Buckets></Buckets></ListAllMyBucketsResult> [ ucloud ] root@master0:~/.kube# RGW\u9ad8\u53ef\u7528 \u00b6 $ vim object.yaml 54 instances: 2 \u521b\u5efaBucket \u00b6 \u521b\u5efastorageclass $ k apply -f storageclass-bucket-delete.yaml storageclass.storage.k8s.io/rook-ceph-delete-bucket created \u521b\u5efabucket $ k apply -f object-bucket-claim-delete.yaml objectbucketclaim.objectbucket.io/ceph-delete-bucket created \u5bb9\u5668\u8bbf\u95ee\u5bf9\u8c61\u5b58\u50a8 \u00b6 \u83b7\u53d6ceph-rgw\u7684\u8bbf\u95ee\u5730\u5740 $ k get cm ceph-delete-bucket -o yaml apiVersion : v1 data : BUCKET_HOST : rook-ceph-rgw-my-store.rook-ceph.svc BUCKET_NAME : ceph-bkt-148b1fa5-7868-42e5-8135-383d357c41cd BUCKET_PORT : \"80\" BUCKET_REGION : us-east-1 BUCKET_SUBREGION : \"\" kind : ConfigMap metadata : creationTimestamp : \"2022-08-05T08:24:27Z\" finalizers : - objectbucket.io/finalizer labels : bucket-provisioner : rook-ceph.ceph.rook.io-bucket name : ceph-delete-bucket namespace : rook-ceph ownerReferences : - apiVersion : objectbucket.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ObjectBucketClaim name : ceph-delete-bucket uid : a8c69ebc-1e4d-477c-97e7-479b532962b3 resourceVersion : \"1282724\" uid : 26786f4b-9371-46fa-8ca9-f470e5e92cb2 \u62ff\u5230secrets $ k get secrets ceph-delete-bucket -o yaml apiVersion : v1 data : AWS_ACCESS_KEY_ID : Rk9JSjxxBJNlg0NDVNUVVMVkpGMzc= AWS_SECRET_ACCESS_KEY : xxxxxxxxxxxxxxxxxxxxxxxxx== kind : Secret metadata : creationTimestamp : \"2022-08-05T08:24:27Z\" finalizers : - objectbucket.io/finalizer labels : bucket-provisioner : rook-ceph.ceph.rook.io-bucket name : ceph-delete-bucket namespace : rook-ceph ownerReferences : - apiVersion : objectbucket.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ObjectBucketClaim name : ceph-delete-bucket uid : a8c69ebc-1e4d-477c-97e7-479b532962b3 resourceVersion : \"1282723\" uid : 1b0af759-7c7d-4fe4-9a80-ea2615fa8fef type : Opaque base64 \u89e3\u5bc6 $ echo Rk9JSjBJNlg0NDVNUVVMVkpGMzc = | base64 -d FOIJ0I6X4xxxxxxx45MQULVJF37% # beiyiwangdejiyi @ beiyiwangdejiyideMacBook-Pro in ~/note-work/hugo on git:main x [14:28:13] $ echo SVdjaElaeVdUbTNGNkRyZ29UcxxxxxxxUQ0R1gzOVlhczR4S1ZmWExERHNYeA == | base64 -d IWchxxxxxxxxxxxxxxxxxxxx% fio --name=sequential-read --directory=/config --rw=read --refill_buffers --bs=4K --size=200M root@nginx-run-685fdf6467-mdl9v:/# fio --name = sequential-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M sequential-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-read: Laying out IO file ( 1 file / 200MiB ) sequential-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 723 : Wed Aug 10 06 :28:37 2022 read: IOPS = 98 .8k, BW = 386MiB/s ( 405MB/s )( 200MiB/518msec ) clat ( nsec ) : min = 378 , max = 86956k, avg = 9833 .73, stdev = 534902 .03 lat ( nsec ) : min = 411 , max = 86956k, avg = 9868 .39, stdev = 534902 .42 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 486 ] , 10 .00th =[ 532 ] , | 20 .00th =[ 556 ] , 30 .00th =[ 580 ] , 40 .00th =[ 604 ] , | 50 .00th =[ 628 ] , 60 .00th =[ 644 ] , 70 .00th =[ 668 ] , | 80 .00th =[ 708 ] , 90 .00th =[ 804 ] , 95 .00th =[ 932 ] , | 99 .00th =[ 70144 ] , 99 .50th =[ 102912 ] , 99 .90th =[ 456704 ] , | 99 .95th =[ 1253376 ] , 99 .99th =[ 26083328 ] bw ( KiB/s ) : min = 401376 , max = 401376 , per = 100 .00%, avg = 401376 .00, stdev = 0 .00, samples = 1 iops : min = 100344 , max = 100344 , avg = 100344 .00, stdev = 0 .00, samples = 1 lat ( nsec ) : 500 = 5 .72%, 750 = 80 .66%, 1000 = 9 .78% lat ( usec ) : 2 = 1 .74%, 4 = 0 .06%, 10 = 0 .17%, 20 = 0 .06%, 50 = 0 .11% lat ( usec ) : 100 = 1 .17%, 250 = 0 .37%, 500 = 0 .07%, 750 = 0 .02%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .02%, 4 = 0 .01%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01% cpu : usr = 3 .29%, sys = 17 .02%, ctx = 571 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 386MiB/s ( 405MB/s ) , 386MiB/s-386MiB/s ( 405MB/s-405MB/s ) , io = 200MiB ( 210MB ) , run = 518 -518msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M sequential-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 729 : Wed Aug 10 06 :30:48 2022 read: IOPS = 344k, BW = 1342MiB/s ( 1407MB/s )( 200MiB/149msec ) clat ( nsec ) : min = 375 , max = 7097 .8k, avg = 2339 .11, stdev = 39079 .52 lat ( nsec ) : min = 406 , max = 7097 .8k, avg = 2372 .97, stdev = 39080 .14 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 524 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 588 ] , 40 .00th =[ 612 ] , | 50 .00th =[ 628 ] , 60 .00th =[ 644 ] , 70 .00th =[ 668 ] , | 80 .00th =[ 700 ] , 90 .00th =[ 748 ] , 95 .00th =[ 868 ] , | 99 .00th =[ 67072 ] , 99 .50th =[ 73216 ] , 99 .90th =[ 114176 ] , | 99 .95th =[ 156672 ] , 99 .99th =[ 1122304 ] lat ( nsec ) : 500 = 2 .29%, 750 = 87 .79%, 1000 = 7 .05% lat ( usec ) : 2 = 0 .96%, 4 = 0 .01%, 10 = 0 .15%, 20 = 0 .04%, 50 = 0 .11% lat ( usec ) : 100 = 1 .42%, 250 = 0 .15%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2 = 0 .02%, 4 = 0 .01%, 10 = 0 .01% cpu : usr = 25 .68%, sys = 49 .32%, ctx = 335 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 1342MiB/s ( 1407MB/s ) , 1342MiB/s-1342MiB/s ( 1407MB/s-1407MB/s ) , io = 200MiB ( 210MB ) , run = 149 -149msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = big-file-multi-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.25 Starting 6 processes big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) Jobs: 2 ( f = 2 ) : [ _ ( 4 ) ,R ( 2 )][ 100 .0% ][ r = 264MiB/s ][ r = 67 .7k IOPS ][ eta 00m:00s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 732 : Wed Aug 10 06 :32:40 2022 read: IOPS = 11 .1k, BW = 43 .5MiB/s ( 45 .6MB/s )( 200MiB/4602msec ) clat ( nsec ) : min = 377 , max = 522247k, avg = 89494 .70, stdev = 4682750 .76 lat ( nsec ) : min = 408 , max = 522247k, avg = 89553 .19, stdev = 4682751 .34 clat percentiles ( nsec ) : | 1 .00th =[ 414 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 692 ] , 60 .00th =[ 732 ] , 70 .00th =[ 796 ] , | 80 .00th =[ 884 ] , 90 .00th =[ 1020 ] , 95 .00th =[ 1192 ] , | 99 .00th =[ 83456 ] , 99 .50th =[ 218112 ] , 99 .90th =[ 5144576 ] , | 99 .95th =[ 20578304 ] , 99 .99th =[ 240123904 ] bw ( KiB/s ) : min = 14080 , max = 90112 , per = 18 .59%, avg = 45625 .50, stdev = 27571 .34, samples = 8 iops : min = 3520 , max = 22528 , avg = 11406 .37, stdev = 6892 .84, samples = 8 lat ( nsec ) : 500 = 3 .47%, 750 = 60 .05%, 1000 = 25 .67% lat ( usec ) : 2 = 8 .49%, 4 = 0 .21%, 10 = 0 .15%, 20 = 0 .08%, 50 = 0 .07% lat ( usec ) : 100 = 1 .00%, 250 = 0 .33%, 500 = 0 .14%, 750 = 0 .07%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .05%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .02%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .59%, sys = 2 .00%, ctx = 671 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 733 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .7k, BW = 41 .9MiB/s ( 43 .9MB/s )( 200MiB/4776msec ) clat ( nsec ) : min = 376 , max = 734234k, avg = 92901 .06, stdev = 5934361 .60 lat ( nsec ) : min = 411 , max = 734234k, avg = 92951 .67, stdev = 5934362 .28 clat percentiles ( nsec ) : | 1 .00th =[ 402 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 588 ] , 30 .00th =[ 636 ] , 40 .00th =[ 684 ] , | 50 .00th =[ 732 ] , 60 .00th =[ 788 ] , 70 .00th =[ 860 ] , | 80 .00th =[ 940 ] , 90 .00th =[ 1080 ] , 95 .00th =[ 1272 ] , | 99 .00th =[ 91648 ] , 99 .50th =[ 193536 ] , 99 .90th =[ 3981312 ] , | 99 .95th =[ 27131904 ] , 99 .99th =[ 233832448 ] bw ( KiB/s ) : min = 8192 , max = 98304 , per = 19 .42%, avg = 47655 .75, stdev = 31431 .05, samples = 8 iops : min = 2048 , max = 24576 , avg = 11913 .88, stdev = 7857 .79, samples = 8 lat ( nsec ) : 500 = 3 .87%, 750 = 50 .45%, 1000 = 31 .27% lat ( usec ) : 2 = 12 .03%, 4 = 0 .18%, 10 = 0 .15%, 20 = 0 .07%, 50 = 0 .06% lat ( usec ) : 100 = 1 .02%, 250 = 0 .48%, 500 = 0 .15%, 750 = 0 .05%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .05%, 4 = 0 .02%, 10 = 0 .03%, 20 = 0 .02%, 50 = 0 .02% lat ( msec ) : 100 = 0 .02%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .44%, sys = 2 .07%, ctx = 845 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 734 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .9k, BW = 42 .6MiB/s ( 44 .7MB/s )( 200MiB/4696msec ) clat ( nsec ) : min = 379 , max = 607583k, avg = 91313 .18, stdev = 4982310 .93 lat ( nsec ) : min = 412 , max = 607583k, avg = 91361 .07, stdev = 4982311 .06 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 700 ] , 60 .00th =[ 740 ] , 70 .00th =[ 804 ] , | 80 .00th =[ 900 ] , 90 .00th =[ 1048 ] , 95 .00th =[ 1240 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 130560 ] , 99 .90th =[ 4882432 ] , | 99 .95th =[ 14483456 ] , 99 .99th =[ 254803968 ] bw ( KiB/s ) : min = 7680 , max = 90112 , per = 17 .01%, avg = 41739 .89, stdev = 24407 .57, samples = 9 iops : min = 1920 , max = 22528 , avg = 10434 .89, stdev = 6101 .90, samples = 9 lat ( nsec ) : 500 = 3 .93%, 750 = 58 .07%, 1000 = 25 .64% lat ( usec ) : 2 = 10 .13%, 4 = 0 .22%, 10 = 0 .13%, 20 = 0 .04%, 50 = 0 .08% lat ( usec ) : 100 = 1 .10%, 250 = 0 .34%, 500 = 0 .08%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .04%, 4 = 0 .03%, 10 = 0 .04%, 20 = 0 .02%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .72%, sys = 1 .81%, ctx = 502 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 735 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .6k, BW = 41 .5MiB/s ( 43 .5MB/s )( 200MiB/4822msec ) clat ( nsec ) : min = 374 , max = 700599k, avg = 93757 .53, stdev = 5099889 .71 lat ( nsec ) : min = 413 , max = 700599k, avg = 93803 .83, stdev = 5099890 .00 clat percentiles ( nsec ) : | 1 .00th =[ 430 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 692 ] , 60 .00th =[ 732 ] , 70 .00th =[ 804 ] , | 80 .00th =[ 900 ] , 90 .00th =[ 1048 ] , 95 .00th =[ 1256 ] , | 99 .00th =[ 91648 ] , 99 .50th =[ 226304 ] , 99 .90th =[ 5931008 ] , | 99 .95th =[ 24248320 ] , 99 .99th =[ 235929600 ] bw ( KiB/s ) : min = 6520 , max = 65536 , per = 15 .07%, avg = 36989 .89, stdev = 18379 .13, samples = 9 iops : min = 1630 , max = 16384 , avg = 9247 .44, stdev = 4594 .77, samples = 9 lat ( nsec ) : 500 = 3 .74%, 750 = 59 .39%, 1000 = 24 .25% lat ( usec ) : 2 = 10 .19%, 4 = 0 .22%, 10 = 0 .18%, 20 = 0 .08%, 50 = 0 .08% lat ( usec ) : 100 = 0 .96%, 250 = 0 .43%, 500 = 0 .14%, 750 = 0 .07%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .06%, 20 = 0 .02%, 50 = 0 .02% lat ( msec ) : 100 = 0 .01%, 250 = 0 .02%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .21%, sys = 2 .24%, ctx = 874 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 736 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .2k, BW = 39 .9MiB/s ( 41 .9MB/s )( 200MiB/5008msec ) clat ( nsec ) : min = 377 , max = 806541k, avg = 97234 .58, stdev = 6320832 .41 lat ( nsec ) : min = 414 , max = 806541k, avg = 97345 .92, stdev = 6320844 .03 clat percentiles ( nsec ) : | 1 .00th =[ 402 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 612 ] , 40 .00th =[ 652 ] , | 50 .00th =[ 684 ] , 60 .00th =[ 724 ] , 70 .00th =[ 772 ] , | 80 .00th =[ 868 ] , 90 .00th =[ 1032 ] , 95 .00th =[ 1240 ] , | 99 .00th =[ 80384 ] , 99 .50th =[ 154624 ] , 99 .90th =[ 5275648 ] , | 99 .95th =[ 20054016 ] , 99 .99th =[ 200278016 ] bw ( KiB/s ) : min = 8192 , max = 49152 , per = 12 .40%, avg = 30434 .00, stdev = 15445 .75, samples = 9 iops : min = 2048 , max = 12288 , avg = 7608 .44, stdev = 3861 .51, samples = 9 lat ( nsec ) : 500 = 3 .77%, 750 = 62 .98%, 1000 = 22 .07% lat ( usec ) : 2 = 8 .67%, 4 = 0 .18%, 10 = 0 .26%, 20 = 0 .12%, 50 = 0 .12% lat ( usec ) : 100 = 1 .05%, 250 = 0 .40%, 500 = 0 .11%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .05%, 4 = 0 .04%, 10 = 0 .03%, 20 = 0 .03%, 50 = 0 .02% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .46%, sys = 1 .96%, ctx = 787 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 737 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .3k, BW = 40 .2MiB/s ( 42 .1MB/s )( 200MiB/4977msec ) clat ( nsec ) : min = 378 , max = 894860k, avg = 96613 .11, stdev = 5799729 .12 lat ( nsec ) : min = 413 , max = 894860k, avg = 96658 .78, stdev = 5799729 .19 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 506 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 612 ] , 40 .00th =[ 644 ] , | 50 .00th =[ 676 ] , 60 .00th =[ 716 ] , 70 .00th =[ 764 ] , | 80 .00th =[ 852 ] , 90 .00th =[ 988 ] , 95 .00th =[ 1176 ] , | 99 .00th =[ 87552 ] , 99 .50th =[ 216064 ] , 99 .90th =[ 6848512 ] , | 99 .95th =[ 31064064 ] , 99 .99th =[ 231735296 ] bw ( KiB/s ) : min = 16929 , max = 69632 , per = 14 .42%, avg = 35383 .25, stdev = 17459 .47, samples = 8 iops : min = 4232 , max = 17408 , avg = 8845 .75, stdev = 4364 .90, samples = 8 lat ( nsec ) : 500 = 4 .66%, 750 = 63 .16%, 1000 = 22 .55% lat ( usec ) : 2 = 7 .10%, 4 = 0 .20%, 10 = 0 .27%, 20 = 0 .09%, 50 = 0 .11% lat ( usec ) : 100 = 0 .99%, 250 = 0 .44%, 500 = 0 .12%, 750 = 0 .07%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .03%, 20 = 0 .03%, 50 = 0 .01% lat ( msec ) : 100 = 0 .02%, 250 = 0 .02%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .32%, sys = 2 .05%, ctx = 1006 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 240MiB/s ( 251MB/s ) , 39 .9MiB/s-43.5MiB/s ( 41 .9MB/s-45.6MB/s ) , io = 1200MiB ( 1258MB ) , run = 4602 -5008msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = big-file-multi-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.25 Starting 6 processes Jobs: 3 ( f = 3 ) : [ _ ( 1 ) ,R ( 1 ) ,_ ( 1 ) ,R ( 1 ) ,_ ( 1 ) ,R ( 1 )][ 80 .0% ][ r = 172MiB/s ][ r = 44 .1k IOPS ][ eta 00m:02s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 740 : Wed Aug 10 06 :34:00 2022 read: IOPS = 8276 , BW = 32 .3MiB/s ( 33 .9MB/s )( 200MiB/6186msec ) clat ( nsec ) : min = 378 , max = 805881k, avg = 120250 .60, stdev = 7449083 .91 lat ( nsec ) : min = 410 , max = 805881k, avg = 120301 .98, stdev = 7449084 .14 clat percentiles ( nsec ) : | 1 .00th =[ 422 ] , 5 .00th =[ 532 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 612 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 660 ] , 60 .00th =[ 684 ] , 70 .00th =[ 716 ] , | 80 .00th =[ 748 ] , 90 .00th =[ 860 ] , 95 .00th =[ 996 ] , | 99 .00th =[ 77312 ] , 99 .50th =[ 132096 ] , 99 .90th =[ 1318912 ] , | 99 .95th =[ 10289152 ] , 99 .99th =[ 434110464 ] bw ( KiB/s ) : min = 8192 , max = 65536 , per = 23 .93%, avg = 35045 .82, stdev = 25507 .11, samples = 11 iops : min = 2048 , max = 16384 , avg = 8761 .45, stdev = 6376 .78, samples = 11 lat ( nsec ) : 500 = 2 .40%, 750 = 77 .33%, 1000 = 15 .36% lat ( usec ) : 2 = 2 .64%, 4 = 0 .06%, 10 = 0 .18%, 20 = 0 .11%, 50 = 0 .13% lat ( usec ) : 100 = 1 .11%, 250 = 0 .39%, 500 = 0 .09%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .03%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .34%, sys = 1 .62%, ctx = 845 , majf = 0 , minf = 14 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 741 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6102 , BW = 23 .8MiB/s ( 24 .0MB/s )( 200MiB/8390msec ) clat ( nsec ) : min = 379 , max = 1190 .5M, avg = 162758 .58, stdev = 11051920 .43 lat ( nsec ) : min = 413 , max = 1190 .5M, avg = 162807 .90, stdev = 11051920 .69 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 524 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 604 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 668 ] , 60 .00th =[ 700 ] , 70 .00th =[ 724 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1004 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 156672 ] , 99 .90th =[ 1073152 ] , | 99 .95th =[ 5275648 ] , 99 .99th =[ 616562688 ] bw ( KiB/s ) : min = 512 , max = 73728 , per = 20 .69%, avg = 30307 .20, stdev = 21673 .33, samples = 10 iops : min = 128 , max = 18432 , avg = 7576 .80, stdev = 5418 .33, samples = 10 lat ( nsec ) : 500 = 2 .76%, 750 = 73 .76%, 1000 = 18 .35% lat ( usec ) : 2 = 2 .79%, 4 = 0 .04%, 10 = 0 .22%, 20 = 0 .13%, 50 = 0 .14% lat ( usec ) : 100 = 1 .05%, 250 = 0 .42%, 500 = 0 .14%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .02%, 20 = 0 .01%, 100 = 0 .01% lat ( msec ) : 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .33%, sys = 1 .10%, ctx = 982 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 742 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6906 , BW = 26 .0MiB/s ( 28 .3MB/s )( 200MiB/7413msec ) clat ( nsec ) : min = 380 , max = 1034 .3M, avg = 144218 .03, stdev = 9148025 .05 lat ( nsec ) : min = 414 , max = 1034 .3M, avg = 144254 .80, stdev = 9148025 .00 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 524 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 596 ] , 40 .00th =[ 620 ] , | 50 .00th =[ 652 ] , 60 .00th =[ 676 ] , 70 .00th =[ 708 ] , | 80 .00th =[ 748 ] , 90 .00th =[ 860 ] , 95 .00th =[ 988 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 146432 ] , 99 .90th =[ 1253376 ] , | 99 .95th =[ 4620288 ] , 99 .99th =[ 522190848 ] bw ( KiB/s ) : min = 16384 , max = 73728 , per = 26 .85%, avg = 39318 .40, stdev = 23491 .33, samples = 10 iops : min = 4096 , max = 18432 , avg = 9829 .60, stdev = 5872 .83, samples = 10 lat ( nsec ) : 500 = 3 .29%, 750 = 76 .66%, 1000 = 15 .22% lat ( usec ) : 2 = 2 .43%, 4 = 0 .10%, 10 = 0 .23%, 20 = 0 .12%, 50 = 0 .12% lat ( usec ) : 100 = 1 .13%, 250 = 0 .37%, 500 = 0 .13%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2000 = 0 .01% cpu : usr = 0 .32%, sys = 1 .32%, ctx = 864 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 743 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6106 , BW = 23 .9MiB/s ( 25 .0MB/s )( 200MiB/8385msec ) clat ( nsec ) : min = 380 , max = 1507 .9M, avg = 162772 .24, stdev = 13174473 .96 lat ( nsec ) : min = 414 , max = 1507 .9M, avg = 162810 .08, stdev = 13174473 .94 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 510 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 604 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 668 ] , 60 .00th =[ 692 ] , 70 .00th =[ 724 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1012 ] , | 99 .00th =[ 79360 ] , 99 .50th =[ 136192 ] , 99 .90th =[ 897024 ] , | 99 .95th =[ 2506752 ] , 99 .99th =[ 434110464 ] bw ( KiB/s ) : min = 8 , max = 81920 , per = 20 .70%, avg = 30310 .40, stdev = 22461 .38, samples = 10 iops : min = 2 , max = 20480 , avg = 7577 .60, stdev = 5615 .35, samples = 10 lat ( nsec ) : 500 = 4 .29%, 750 = 73 .14%, 1000 = 17 .30% lat ( usec ) : 2 = 2 .94%, 4 = 0 .04%, 10 = 0 .22%, 20 = 0 .07%, 50 = 0 .19% lat ( usec ) : 100 = 1 .10%, 250 = 0 .44%, 500 = 0 .11%, 750 = 0 .05%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .03%, 4 = 0 .01%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .05%, sys = 1 .40%, ctx = 993 , majf = 0 , minf = 14 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 744 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6911 , BW = 26 .0MiB/s ( 28 .3MB/s )( 200MiB/7408msec ) clat ( nsec ) : min = 381 , max = 1179 .3M, avg = 143994 .58, stdev = 11079777 .48 lat ( nsec ) : min = 413 , max = 1179 .3M, avg = 144029 .70, stdev = 11079777 .45 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 580 ] , 40 .00th =[ 612 ] , | 50 .00th =[ 636 ] , 60 .00th =[ 668 ] , 70 .00th =[ 692 ] , | 80 .00th =[ 732 ] , 90 .00th =[ 836 ] , 95 .00th =[ 956 ] , | 99 .00th =[ 76288 ] , 99 .50th =[ 111104 ] , 99 .90th =[ 995328 ] , | 99 .95th =[ 3227648 ] , 99 .99th =[ 742391808 ] bw ( KiB/s ) : min = 5040 , max = 73728 , per = 22 .93%, avg = 33587 .20, stdev = 27492 .28, samples = 10 iops : min = 1260 , max = 18432 , avg = 8396 .80, stdev = 6873 .07, samples = 10 lat ( nsec ) : 500 = 3 .81%, 750 = 78 .93%, 1000 = 13 .08% lat ( usec ) : 2 = 2 .02%, 4 = 0 .02%, 10 = 0 .21%, 20 = 0 .07%, 50 = 0 .12% lat ( usec ) : 100 = 1 .15%, 250 = 0 .36%, 500 = 0 .07%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .26%, sys = 1 .35%, ctx = 724 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 745 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6238 , BW = 24 .4MiB/s ( 25 .6MB/s )( 200MiB/8207msec ) clat ( nsec ) : min = 379 , max = 1170 .8M, avg = 159639 .78, stdev = 10672683 .50 lat ( nsec ) : min = 413 , max = 1170 .8M, avg = 159675 .27, stdev = 10672683 .47 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 596 ] , 40 .00th =[ 628 ] , | 50 .00th =[ 652 ] , 60 .00th =[ 684 ] , 70 .00th =[ 716 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1012 ] , | 99 .00th =[ 77312 ] , 99 .50th =[ 156672 ] , 99 .90th =[ 1810432 ] , | 99 .95th =[ 5865472 ] , 99 .99th =[ 616562688 ] bw ( KiB/s ) : min = 6400 , max = 74752 , per = 18 .50%, avg = 27096 .62, stdev = 22310 .47, samples = 13 iops : min = 1600 , max = 18688 , avg = 6774 .15, stdev = 5577 .62, samples = 13 lat ( nsec ) : 500 = 4 .00%, 750 = 74 .22%, 1000 = 16 .52% lat ( usec ) : 2 = 3 .01%, 4 = 0 .05%, 10 = 0 .19%, 20 = 0 .07%, 50 = 0 .11% lat ( usec ) : 100 = 1 .06%, 250 = 0 .40%, 500 = 0 .14%, 750 = 0 .05%, 1000 = 0 .05% lat ( msec ) : 2 = 0 .04%, 4 = 0 .03%, 10 = 0 .03%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2000 = 0 .01% cpu : usr = 0 .26%, sys = 1 .22%, ctx = 949 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 143MiB/s ( 150MB/s ) , 23 .8MiB/s-32.3MiB/s ( 24 .0MB/s-33.9MB/s ) , io = 1200MiB ( 1258MB ) , run = 6186 -8390msec fio --name=sequential-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --end_fsync=1 fio --name=big-file-multi-read --directory=$PWD --rw=read --refill_buffers --bs=4K --size=200M --numjobs=6 fio --name=sequential-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --end_fsync=1 root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-write --directory = /config --rw = write --refill_buffers --bs = 4K --size = 200M --end_fsync = 1 sequential-write: ( g = 0 ) : rw = write, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-write: Laying out IO file ( 1 file / 200MiB ) Jobs: 1 ( f = 1 ) sequential-write: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 756 : Wed Aug 10 06 :39:40 2022 write: IOPS = 33 .6k, BW = 131MiB/s ( 138MB/s )( 200MiB/1525msec ) ; 0 zone resets clat ( usec ) : min = 7 , max = 7420 , avg = 27 .69, stdev = 125 .85 lat ( usec ) : min = 7 , max = 7420 , avg = 27 .76, stdev = 125 .85 clat percentiles ( usec ) : | 1 .00th =[ 8 ] , 5 .00th =[ 9 ] , 10 .00th =[ 11 ] , 20 .00th =[ 12 ] , | 30 .00th =[ 20 ] , 40 .00th =[ 21 ] , 50 .00th =[ 22 ] , 60 .00th =[ 22 ] , | 70 .00th =[ 23 ] , 80 .00th =[ 24 ] , 90 .00th =[ 28 ] , 95 .00th =[ 37 ] , | 99 .00th =[ 118 ] , 99 .50th =[ 285 ] , 99 .90th =[ 1860 ] , 99 .95th =[ 3097 ] , | 99 .99th =[ 4752 ] bw ( KiB/s ) : min = 132286 , max = 138088 , per = 100 .00%, avg = 135187 .00, stdev = 4102 .63, samples = 2 iops : min = 33071 , max = 34522 , avg = 33796 .50, stdev = 1026 .01, samples = 2 lat ( usec ) : 10 = 9 .54%, 20 = 24 .43%, 50 = 63 .08%, 100 = 1 .75%, 250 = 0 .66% lat ( usec ) : 500 = 0 .22%, 750 = 0 .09%, 1000 = 0 .05% lat ( msec ) : 2 = 0 .10%, 4 = 0 .07%, 10 = 0 .03% cpu : usr = 9 .84%, sys = 31 .04%, ctx = 51905 , majf = 0 , minf = 12 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 0 ,51200,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : WRITE: bw = 131MiB/s ( 138MB/s ) , 131MiB/s-131MiB/s ( 138MB/s-138MB/s ) , io = 200MiB ( 210MB ) , run = 1525 -1525msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-write --directory = /config --rw = write --refill_buffers --bs = 4K --size = 200M --end_fsync = 1 sequential-write: ( g = 0 ) : rw = write, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process Jobs: 1 ( f = 1 ) sequential-write: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 759 : Wed Aug 10 06 :41:20 2022 write: IOPS = 31 .3k, BW = 122MiB/s ( 128MB/s )( 200MiB/1637msec ) ; 0 zone resets clat ( usec ) : min = 7 , max = 9234 , avg = 30 .16, stdev = 137 .54 lat ( usec ) : min = 7 , max = 9234 , avg = 30 .21, stdev = 137 .54 clat percentiles ( usec ) : | 1 .00th =[ 8 ] , 5 .00th =[ 9 ] , 10 .00th =[ 11 ] , 20 .00th =[ 18 ] , | 30 .00th =[ 20 ] , 40 .00th =[ 21 ] , 50 .00th =[ 22 ] , 60 .00th =[ 22 ] , | 70 .00th =[ 23 ] , 80 .00th =[ 24 ] , 90 .00th =[ 29 ] , 95 .00th =[ 41 ] , | 99 .00th =[ 147 ] , 99 .50th =[ 379 ] , 99 .90th =[ 2311 ] , 99 .95th =[ 3064 ] , | 99 .99th =[ 4490 ] bw ( KiB/s ) : min = 119544 , max = 132640 , per = 100 .00%, avg = 128018 .67, stdev = 7349 .32, samples = 3 iops : min = 29886 , max = 33160 , avg = 32004 .67, stdev = 1837 .33, samples = 3 lat ( usec ) : 10 = 7 .32%, 20 = 25 .16%, 50 = 63 .95%, 100 = 2 .08%, 250 = 0 .85% lat ( usec ) : 500 = 0 .23%, 750 = 0 .09%, 1000 = 0 .08% lat ( msec ) : 2 = 0 .12%, 4 = 0 .11%, 10 = 0 .02% cpu : usr = 7 .21%, sys = 32 .64%, ctx = 51971 , majf = 0 , minf = 13 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 0 ,51200,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : WRITE: bw = 122MiB/s ( 128MB/s ) , 122MiB/s-122MiB/s ( 128MB/s-128MB/s ) , io = 200MiB ( 210MB ) , run = 1637 -1637msec fio --name=big-file-multi-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --numjobs=6 --end_fsync=1 fio -filename=/config/fio.img -direct=1 -iodepth 32 -thread -rw=randread -ioengine=libaio -bs=4k -size=200m -numjobs=2 -runtime=60 -group_reporting -name=mytest \u56fa\u6001\u5bbf\u4e3b\u673a\uff1a [ ucloud ] root@node1:/var/jfsCache# fio --name = big-file-multi-read --directory = $PWD --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.16 Starting 6 processes Jobs: 6 ( f = 6 ) : [ R ( 6 )][ 88 .9% ][ r = 130MiB/s ][ r = 33 .2k IOPS ][ eta 00m:01s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 225237 : Fri Aug 12 14 :09:04 2022 read: IOPS = 5925 , BW = 23 .1MiB/s ( 24 .3MB/s )( 200MiB/8641msec ) clat ( nsec ) : min = 434 , max = 21757k, avg = 168221 .11, stdev = 1662876 .10 lat ( nsec ) : min = 471 , max = 21757k, avg = 168260 .51, stdev = 1662876 .63 clat percentiles ( nsec ) : | 1 .00th =[ 524 ] , 5 .00th =[ 540 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 572 ] , 40 .00th =[ 580 ] , | 50 .00th =[ 596 ] , 60 .00th =[ 612 ] , 70 .00th =[ 628 ] , | 80 .00th =[ 660 ] , 90 .00th =[ 732 ] , 95 .00th =[ 884 ] , | 99 .00th =[ 3948544 ] , 99 .50th =[ 19005440 ] , 99 .90th =[ 20054016 ] , | 99 .95th =[ 20054016 ] , 99 .99th =[ 20054016 ] \u5185\u5b58\u5bbf\u4e3b\u673a\uff1a [ ucloud ] root@node1:/var/jfsCache# fio --name = big-file-multi-read --directory = $PWD --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.16 Starting 6 processes big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 12095 : Fri Aug 12 15 :05:27 2022 read: IOPS = 966k, BW = 3774MiB/s ( 3957MB/s )( 200MiB/53msec ) clat ( nsec ) : min = 520 , max = 221610 , avg = 757 .38, stdev = 2561 .09 lat ( nsec ) : min = 553 , max = 221646 , avg = 792 .50, stdev = 2561 .18 clat percentiles ( nsec ) : | 1 .00th =[ 540 ] , 5 .00th =[ 556 ] , 10 .00th =[ 556 ] , 20 .00th =[ 564 ] , | 30 .00th =[ 572 ] , 40 .00th =[ 580 ] , 50 .00th =[ 596 ] , 60 .00th =[ 612 ] , | 70 .00th =[ 644 ] , 80 .00th =[ 724 ] , 90 .00th =[ 908 ] , 95 .00th =[ 940 ] , | 99 .00th =[ 3344 ] , 99 .50th =[ 3728 ] , 99 .90th =[ 19072 ] , 99 .95th =[ 43264 ] , | 99 .99th =[ 115200 ] fio --name=small-file-multi-read \\ --directory=/config \\ --rw=read --file_service_type=sequential \\ --bs=4k --filesize=4k --nrfiles=500 \\ --numjobs=2","title":"rook-ceph\u7b80\u4ecb"},{"location":"Storage/rook-ceph/#rook-ceph","text":"","title":"rook-ceph\u7b80\u4ecb\u548c\u90e8\u7f72"},{"location":"Storage/rook-ceph/#rook-ceph_1","text":"\u5f00\u6e90\u7684\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\uff0c\u652f\u6301\u5bf9\u8c61\u5b58\u50a8\uff0c\u5757\u8bbe\u5907\uff0c\u6587\u4ef6\u7cfb\u7edf \u5757\u5b58\u50a8 CephFs \u5bf9\u8c61\u5b58\u50a8","title":"rook-ceph\u7b80\u4ecb"},{"location":"Storage/rook-ceph/#ceph","text":"x.0.z - \u5f00\u53d1\u7248 x.1.z - \u5019\u9009\u7248 x.2.z - \u7a33\u5b9a\uff0c\u4fee\u6b63\u7248","title":"ceph \u7684\u7248\u672c\u5386\u53f2"},{"location":"Storage/rook-ceph/#ceph_1","text":"\u6ce8\u610f ceph\u96c6\u7fa4\u7684osd\u8282\u70b9\u4e00\u822c\u4fdd\u8bc1>=3\u4e2a\uff0c\u6765\u4fdd\u8bc1\u6570\u636e\u7684\u9ad8\u53ef\u7528\u6027\u3002 mon : ceph \u76d1\u89c6\u5668,\u5728\u4e00\u4e2a\u4e3b\u673a\u4e0a\u8fd0\u884c\u7684\u4e00\u4e2a\u5b88\u62a4\u8fdb\u7a0b\uff0c\u7528\u4e8e\u7ef4\u62a4\u96c6\u7fa4\u72b6\u6001\u6620\u5c04\u5173\u7cfb mgr : \u8d1f\u8d23\u8ddf\u8e2a\u8fd0\u884c\u65f6\u6307\u6807\u548cceph\u96c6\u7fa4\u7684\u5f53\u524d\u72b6\u6001 osd : \u78c1\u76d8\uff08\u771f\u6b63\u5b58\u50a8\u6570\u636e\u7684\u5730\u65b9\uff09 ceph \u9762\u8bd5\u9898 ceph","title":"ceph\u96c6\u7fa4\u89d2\u8272\u5b9a\u4e49"},{"location":"Storage/rook-ceph/#rook-ceph_2","text":"\u73af\u5883\u8981\u6c42 \u4e00\u4e2ak8s\u96c6\u7fa4\uff0cnode\u8282\u70b9\u6700\u5c11\u4e09\u4e2a\u8282\u70b9 mon: 8C 8G/200G 16C 16g/32-200G","title":"rook-ceph\u90e8\u7f72"},{"location":"Storage/rook-ceph/#_1","text":"","title":"\u666e\u901a\u6d4b\u8bd5\u90e8\u7f72\uff1a"},{"location":"Storage/rook-ceph/#crdscommonoperator","text":"[ucloud] root@master0:~# git clone --single-branch --branch v1.5.5 https://github.com/rook/rook.git cd rook/cluster/examples/kubernetes/ceph kubectl create -f crds.yaml -f common.yaml -f operator.yaml kubectl create -f cluster.yaml","title":"\u90e8\u7f72crds\uff0ccommon\uff0coperator"},{"location":"Storage/rook-ceph/#_2","text":"# ROOK_CSI_CEPH_IMAGE: \"quay.io/cephcsi/cephcsi:v3.4.0\" # ROOK_CSI_REGISTRAR_IMAGE: \"k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\" # ROOK_CSI_RESIZER_IMAGE: \"k8s.gcr.io/sig-storage/csi-resizer:v1.3.0\" # ROOK_CSI_PROVISIONER_IMAGE: \"k8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\" # ROOK_CSI_SNAPSHOTTER_IMAGE: \"k8s.gcr.io/sig-storage/csi-snapshotter:v4.2.0\" # ROOK_CSI_ATTACHER_IMAGE: \"k8s.gcr.io/sig-storage/csi-attacher:v3.3.0\"","title":"\u955c\u50cf\u5217\u8868\uff1a"},{"location":"Storage/rook-ceph/#csi","text":"[ ucloud ] root@node0:/home/lixie# cat <<EOF>> image-sci.sh #!/bin/bash image_list=' csi-node-driver-registrar:v2.0.1 csi-attacher:v3.0.0 csi-snapshotter:v3.0.0 csi-resizer:v1.0.0 csi-provisioner:v2.0.0 ' aliyuncs=\"registry.aliyuncs.com/it00021hot\" google_gcr=\"k8s.gcr.io/sig-storage\" for image in $image_list do echo $image docker pull ${aliyuncs}/${image} docker tag ${aliyuncs}/${image} ${google_gcr}/${image} docker rm ${aliyuncs}/${image} #echo \"${aliyuncs}/${image} ${google_gcr}/${image} downloaded.\" done EOF","title":"CSI\u83b7\u53d6\u955c\u50cf\u811a\u672c\uff1a"},{"location":"Storage/rook-ceph/#_3","text":"","title":"\u5b9a\u5236\u5316\u90e8\u7f72\uff1a"},{"location":"Storage/rook-ceph/#mon","text":"\u80cc\u666f \u2f63\u4ea7\u73af\u5883\u6709\u2f00\u4e9b\u4e13\u2ed4\u7684\u8282\u70b9\u2f64\u4e8emon\u3001mgr\uff0c\u5b58\u50a8\u8282\u70b9\u8282\u70b9\u4f7f\u2f64\u5355\u72ec\u7684\u8282\u70b9\u627f\u62c5,\u5229\u2f64\u8c03\u5ea6\u673a\u5236\u5b9e \u73b0 placement : mon : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-mon operator : In values : - enabled #\u8bbe\u7f6e\u78c1\u76d8\u7684\u53c2\u6570\uff0c\u8c03\u6574\u4e3afalse\uff0c\u2f45\u4fbf\u540e\u2faf\u5b9a\u5236 214 useAllNodes : false 215 useAllDevices : false \u5206\u522b\u7ed9\u8282\u70b9\u6253\u4e0a\u6807\u7b7e [ucloud] root@master0:~# kubectl label node node0 ceph-mon=enabled node/node0 labeled [ucloud] root@master0:~# kubectl label node node1 ceph-mon=enabled node/node1 labeled [ucloud] root@master0:~# kubectl label node node2 ceph-mon=enabled node/node2 labeled \u83b7\u53d6\u955c\u50cf\u811a\u672c $ cat image-rook-ceph-sci-v1.7.11.sh #!/bin/bash image_list=' csi-node-driver-registrar:v2.0.1 csi-attacher:v3.0.0 csi-snapshotter:v3.0.0 csi-resizer:v1.0.0 csi-provisioner:v2.0.0 ' aliyuncs=\"registry.aliyuncs.com/it00021hot\" google_gcr=\"k8s.gcr.io/sig-storage\" for image in $image_list do echo $image docker pull ${aliyuncs}/${image} docker tag ${aliyuncs}/${image} ${google_gcr}/${image} #docker rm ${aliyuncs}/${image} #echo \"${aliyuncs}/${image} ${google_gcr}/${image} downloaded.\" done EOF","title":"\u5b9a\u5236mon\u8c03\u5ea6\u53c2\u6570"},{"location":"Storage/rook-ceph/#mgr","text":"\u6e29\u99a8\u63d0\u793a \u4fee\u6539mgr\u7684\u8c03\u5ea6\u53c2\u6570,\u4fee\u6539\u5b8c\u4e4b\u540e\u91cd\u65b0apply cluster.yaml\u914d\u7f6e\u4f7f\u5176\u52a0\u8f7d\u5230\u96c6\u7fa4\u4e2d mgr : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-mgr operator : In values : - enabled \u6b64\u65f6\u8c03\u5ea6\u4f1a\u5931\u8d25\uff0c\u7ed9node-1\u548cnode-2\u6253\u4e0a ceph-mgr=enabled \u7684\u6807\u7b7e $ kubectl label nodes node0 ceph-mgr=enabled node/node0 labeled $ kubectl label nodes node1 ceph-mgr=enabled node/node1 labeled","title":"\u5b9a\u5236mgr\u8c03\u5ea6\u53c2\u6570"},{"location":"Storage/rook-ceph/#msd","text":"\u8bbe\u7f6eosd\u7684\u8c03\u5ea6\u53c2\u6570 osd : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : ceph-osd operator : In values : - enabled \u5b9a\u5236osd\u7684\u78c1\u76d8\u53c2\u6570 nodes : - name : \"node0\" devices : # specific devices to use for storage can be specified for each node - name : \"vdb\" - name : \"node1\" devices : # specific devices to use for storage can be specified for each node - name : \"vdc\"","title":"\u5b9a\u5236msd\u8c03\u5ea6\u53c2\u6570"},{"location":"Storage/rook-ceph/#toolbox","text":"apply\u4ee5\u4e0b\u4e2d\u4e24\u4e2a\u6587\u4ef6\u7684\u4e00\u4e2a\u5c31\u53ef\u4ee5\uff0c\u4e00\u822c\u9009\u62e9toolbox.yaml $ ll tool* -rw-r--r-- 1 beiyiwangdejiyi staff 1.7K 7 19 17:26 toolbox-job.yaml # \u4e00\u6b21\u6027\u4efb\u52a1 -rw-r--r-- 1 beiyiwangdejiyi staff 1.4K 7 19 17:26 toolbox.yaml kubectl apply -f toolbox.yaml","title":"toolbox\u5ba2\u6237\u7aef"},{"location":"Storage/rook-ceph/#k8sceph","text":"centos\u7cfb\u7edf\uff1a","title":"k8s\u8bbf\u95eeceph"},{"location":"Storage/rook-ceph/#1-ceph-yum","text":"[root@node-1 ~]# cat /etc/yum.repos.d/ceph.repo [ceph] name=ceph baseurl=https://mirrors.aliyun.com/ceph/rpm-octopus/el8/x86_64/ enabled=1 gpgcheck=0","title":"1. \u914d\u7f6eCeph yum\u6e90"},{"location":"Storage/rook-ceph/#2ceph-common","text":"[root@node-1 ~]# yum -y install ceph-common","title":"2.\u5b89\u88c5ceph-common"},{"location":"Storage/rook-ceph/#3-ceph","text":"[root@rook-ceph-tools-65c94d77bb-b9b2h /]# cat /etc/ceph/ceph.conf # \u67e5\u770b\u4e4b\u540e\u5bbf\u4e3b\u673a\u521b\u5efa [global] mon_host = 10.43.248.216:6789,10.43.174.200:6789,10.43.9.21:6789 [client.admin] keyring = /etc/ceph/keyring [root@rook-ceph-tools-65c94d77bb-b9b2h /]# cat /etc/ceph/keyring # \u67e5\u770b\u4e4b\u540e\u5bbf\u4e3b\u673a\u521b\u5efa [client.admin] key = AQCRS+NijUeiIxAAhFtv6je2FmMEAVHAJJqPwg== ubuntu\u7cfb\u7edf\uff1a apt install ceph-common","title":"3. \u521b\u5efaceph\u914d\u7f6e\u6587\u4ef6"},{"location":"Storage/rook-ceph/#rbd","text":"","title":"\u8bbf\u95eeRBD\u5757\u5b58\u50a8"},{"location":"Storage/rook-ceph/#1pool","text":"[ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # ceph osd pool create rook 16 16 pool 'rook' created [root@rook-ceph-tools-65c94d77bb-xg6xs /]# ceph osd lspools # \u67e5\u770bpools 1 device_health_metrics 2 replicapool 3 rook","title":"1.\u521b\u5efa\u4e00\u4e2apool"},{"location":"Storage/rook-ceph/#2-pool","text":"[ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # rbd create -p rook --image rook-rbd.img --size 10G [ root@rook-ceph-tools-65c94d77bb-xg6xs / ] # rbd ls -p rook rook-rbd.img [root@rook-ceph-tools-65c94d77bb-xg6xs /]# rbd info rook/rook-rbd.img # \u67e5\u770b\u8be6\u7ec6\u4fe1\u606f rbd image 'rook-rbd.img' : size 10 GiB in 2560 objects order 22 (4 MiB objects) snapshot_count : 0 id : 50a7fcf85890 block_name_prefix : rbd_data.50a7fcf85890 format : 2 features : layering op_features : flags : create_timestamp : Fri Jul 29 05:40:05 2022 access_timestamp : Fri Jul 29 05:40:05 2022 modify_timestamp : Fri Jul 29 05:40:05 2022","title":"2. \u5728pool\u4e0a\u521b\u5efa\u5757\u8bbe\u5907"},{"location":"Storage/rook-ceph/#3rbd","text":"[ ucloud ] root@master0:/home/lixie# rbd map rook/rook-rbd.img /dev/rbd0 [ ucloud ] root@master0:/home/lixie# rbd showmapped id pool namespace image snap device 0 rook rook-rbd.img - /dev/rbd0 [ ucloud ] root@master0:/home/lixie# mkfs.xfs /dev/rbd0 meta-data = /dev/rbd1 isize = 512 agcount = 16 , agsize = 163840 blks = sectsz = 512 attr = 2 , projid32bit = 1 = crc = 1 finobt = 1 , sparse = 1 , rmapbt = 0 = reflink = 1 data = bsize = 4096 blocks = 2621440 , imaxpct = 25 = sunit = 16 swidth = 16 blks naming = version 2 bsize = 4096 ascii-ci = 0 , ftype = 1 log = internal log bsize = 4096 blocks = 2560 , version = 2 = sectsz = 512 sunit = 16 blks, lazy-count = 1 realtime = none extsz = 4096 blocks = 0 , rtextents = 0 \u95ee\u9898\u4e00\uff1a\u52a0\u8f7d rbd \u5185\u6838\u6a21\u5757\u5931\u8d25 [root@rook-ceph-tools-65c94d77bb-xg6xs /]# rbd map rook/rook-rbd.img modinfo: ERROR: Module alias rbd not found. modprobe: FATAL: Module rbd not found in directory /lib/modules/5.4.0-48-generic rbd: failed to load rbd kernel module (1) rbd: failed to set udev buffer size: (1) Operation not permitted rbd: sysfs write failed In some cases useful info is found in syslog - try \"dmesg | tail\". rbd: map failed: (2) No such file or directory \u89e3\u51b3\u65b9\u6cd5\uff1a [ucloud] root@node0:/home/lixie# modprobe rbd [ucloud] root@node0:/home/lixie# lsmod |grep rbd rbd 106496 0 libceph 327680 1 rbd \u95ee\u9898\u4e8c\uff1amap rdb [root@rook-ceph-tools-65c94d77bb-b9b2h /]# rbd map rook/rook-rbd.img rbd: failed to set udev buffer size: (1) Operation not permitted rbd: sysfs write failed In some cases useful info is found in syslog - try \"dmesg | tail\". \u89e3\u51b3\u65b9\u6cd5\uff1a \u5728\u5bbf\u4e3b\u673a\u4e0a\u6267\u884c\uff0c\u8be5\u547d\u4ee4\u3002 \u95ee\u9898\u4e09: \u5185\u6838\u6a21\u5757\u4e0d\u652f\u6301\u8fd9\u4e48\u591a\u7684\u7279\u6027 [dev] root@master0:/home/lixie# rbd map rook/rook-rbd1.img rbd: sysfs write failed RBD image feature set mismatch. You can disable features unsupported by the kernel with \"rbd feature disable rook/rook-rbd1.img object-map fast-diff deep-flatten\". In some cases useful info is found in syslog - try \"dmesg | tail\". rbd: map failed: (6) No such device or address \u89e3\u51b3\u65b9\u6cd5\uff1a rbd feature disable rook/rook-rbd1.img object-map fast-diff deep-flatten # \u6309\u7167\u4ed6\u7684\u63d0\u793a\uff0c\u5148\u7981\u6b62\u8fd9\u4e9b\u7279\u6027\u518dmap","title":"3\u3001\u5ba2\u6237\u6302\u8f7dRBD\u5757"},{"location":"Storage/rook-ceph/#dashbaard","text":"\u6e29\u99a8\u63d0\u793a \u6ce8\u610f\u9700\u8981\u5c06\u4e3b\u673a\u66b4\u6f0f\u7aef\u53e3\u7684\u5b89\u5168\u7ec4\u6253\u5f00\uff0c\u5b89\u5168\u7ec4\u6253\u5f00 31926 \u7aef\u53e3 \u542f\u2f64\u4e4b\u540e\uff0c\u53ef\u4ee5\u770b\u5230rook-ceph-mgr-dashboard-external-http\u7684service\uff0c\u5176\u7c7b\u578b\u662fNodePort\uff0c /Users/beiyiwangdejiyi/k8s-data/rook-v1.6.11/cluster/examples/kubernetes/ceph k apply -f dashboard-external-http.yaml $ k get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE csi-cephfsplugin-metrics ClusterIP 10.97.7.142 <none> 8080/TCP,8081/TCP 579d csi-rbdplugin-metrics ClusterIP 10.97.0.194 <none> 8080/TCP,8081/TCP 579d rook-ceph-mgr ClusterIP 10.97.15.77 <none> 9283/TCP 579d rook-ceph-mgr-dashboard ClusterIP 10.97.4.98 <none> 7000/TCP 579d rook-ceph-mgr-dashboard-external-http NodePort 10.97.10.172 <none> 7000:31926/TCP 8m18s \u9ed8\u8ba4mgr\u521b\u5efa\u4e86\u2f00\u4e2aadmin\u7684\u2f64\u6237\uff0c\u5176\u5bc6\u7801\u5b58\u653e\u5728rook-ceph-dashboard-password\u7684secrets\u5bf9\u8c61\u4e2d\uff0c\u901a\u8fc7\u5982\u4e0b\u2f45\u5f0f\u53ef\u4ee5\u83b7\u53d6\u5230 kubectl get secrets -n rook-ceph rook-ceph-dashboard-password -oyaml apiVersion : v1 data : password : XTBndSx0iRxxxEN1xbE9Uxxxx2JQSSE= # \u91c7\u7528base64\u52a0\u5bc6 kind : Secret metadata : creationTimestamp : \"2020-12-16T18:01:16Z\" name : rook-ceph-dashboard-password namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"103972533\" uid : 7082d4ad-47bb-46e2-b439-624016cc5f81 type : kubernetes.io/rook base64 \u89e3\u5bc6 $ echo XTBndS0iREN1bE9UMGpQY2JQSSE= | base64 -d ]0gu-\"DCulOT0jPcbPI!% \u6d4b\u8bd5\u767b\u9646 URL: http://xxxxxxxxx:31926/ \u5e10\u53f7: admin \u5bc6\u7801: xxxxxxxxxx \u8fdb\u5165\u5c31\u53ef\u4ee5\u770b\u5230\u4e00\u4e0b\u754c\u9762","title":"Dashbaard \u56fe\u5f62\u7ba1\u7406"},{"location":"Storage/rook-ceph/#dashboard-ceph","text":"$ k get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE csi-cephfsplugin-metrics ClusterIP 10.97.7.142 <none> 8080/TCP,8081/TCP 580d csi-rbdplugin-metrics ClusterIP 10.97.0.194 <none> 8080/TCP,8081/TCP 580d rook-ceph-mgr ClusterIP 10.97.15.77 <none> 9283/TCP 580d # \u7ed9prometheus\u4f5c\u4e3a\u5ba2\u6237\u7aef\u4f7f\u7528\u7684 ......","title":"Dashboard \u76d1\u63a7ceph"},{"location":"Storage/rook-ceph/#prometheus-operator","text":"kubectl apply -f https://raw.githubusercontent.com/coreos/prometheus-operator/v0.40.0/bundle.yaml \u786e\u8ba4prometheus-operator\u5904\u4e8erun\u72b6\u6001 $ k get pod prometheus-operator-7ccf6dfc8-d9dmm 1/1 Running 0 142","title":"\u90e8\u7f72Prometheus Operator"},{"location":"Storage/rook-ceph/#prometheus-instances","text":"$ git clone --single-branch --branch v1.6.11 https://github.com/rook/rook.git cd rook/cluster/examples/kubernetes/ceph/monitoring \u521b\u5efa\u670d\u52a1\u76d1\u89c6\u5668\u4ee5\u53ca Prometheus \u670d\u52a1\u5668 pod \u548c\u670d\u52a1 kubectl create -f service-monitor.yaml kubectl create -f prometheus.yaml kubectl create -f prometheus-service.yaml \u672c\u5730\u6d4b\u8bd5\u8bbf\u95ee\uff1a $ k port-forward pod/prometheus-rook-prometheus-0 -n rook-ceph 9090 9090 \u8bbf\u95ee\uff1ahttp://localhost:9090/ grafana\u6d4b\u8bd5\u8bbf\u95ee\uff1a $ k port-forward pod/grafana-cc568dbd8-4nvlq -n infra 3000 80 \u8bbf\u95ee\uff1ahttp://localhost:3000/ \u5e10\u53f7\uff1aadmin \u5bc6\u7801\uff1axxxxxxxxxxx \u76d1\u63a7\u5c55\u677f Ceph - Cluster\uff1ahttps://grafana.com/grafana/dashboards/2842 Ceph - OSD \uff1a https://grafana.com/grafana/dashboards/5336 Ceph - Pools\uff1a https://grafana.com/grafana/dashboards/5342","title":"\u90e8\u7f72Prometheus Instances"},{"location":"Storage/rook-ceph/#_4","text":"","title":"\u5bf9\u8c61\u5b58\u50a8"},{"location":"Storage/rook-ceph/#rgw","text":"$ k apply -f object.yaml [ ucloud ] root@master0:~/.kube# kubectl get svc -n rook-ceph NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE csi-rbdplugin-metrics ClusterIP 10 .43.40.164 <none> 8080 /TCP,8081/TCP 7d4h csi-cephfsplugin-metrics ClusterIP 10 .43.170.151 <none> 8080 /TCP,8081/TCP 7d4h rook-ceph-mon-a ClusterIP 10 .43.248.216 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mon-b ClusterIP 10 .43.174.200 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mon-c ClusterIP 10 .43.9.21 <none> 6789 /TCP,3300/TCP 7d4h rook-ceph-mgr-dashboard ClusterIP 10 .43.193.31 <none> 8443 /TCP 7d4h rook-ceph-mgr ClusterIP 10 .43.114.15 <none> 9283 /TCP 7d4h wordpress-mysql ClusterIP None <none> 3306 /TCP 7d3h rook-prometheus NodePort 10 .43.128.1 <none> 9090 :30900/TCP 3d prometheus-operated ClusterIP None <none> 9090 /TCP 3d rook-ceph-rgw-my-store ClusterIP 10 .43.73.235 <none> 80 /TCP 18m [ ucloud ] root@master0:~/.kube# curl http://10.43.73.235 <?xml version = \"1.0\" encoding = \"UTF-8\" ?><ListAllMyBucketsResult xmlns = \"http://s3.amazonaws.com/doc/2006-03-01/\" ><Owner><ID>anonymous</ID><DisplayName></DisplayName></Owner><Buckets></Buckets></ListAllMyBucketsResult> [ ucloud ] root@master0:~/.kube#","title":"\u90e8\u7f72RGW\u5bf9\u8c61\u5b58\u50a8"},{"location":"Storage/rook-ceph/#rgw_1","text":"$ vim object.yaml 54 instances: 2","title":"RGW\u9ad8\u53ef\u7528"},{"location":"Storage/rook-ceph/#bucket","text":"\u521b\u5efastorageclass $ k apply -f storageclass-bucket-delete.yaml storageclass.storage.k8s.io/rook-ceph-delete-bucket created \u521b\u5efabucket $ k apply -f object-bucket-claim-delete.yaml objectbucketclaim.objectbucket.io/ceph-delete-bucket created","title":"\u521b\u5efaBucket"},{"location":"Storage/rook-ceph/#_5","text":"\u83b7\u53d6ceph-rgw\u7684\u8bbf\u95ee\u5730\u5740 $ k get cm ceph-delete-bucket -o yaml apiVersion : v1 data : BUCKET_HOST : rook-ceph-rgw-my-store.rook-ceph.svc BUCKET_NAME : ceph-bkt-148b1fa5-7868-42e5-8135-383d357c41cd BUCKET_PORT : \"80\" BUCKET_REGION : us-east-1 BUCKET_SUBREGION : \"\" kind : ConfigMap metadata : creationTimestamp : \"2022-08-05T08:24:27Z\" finalizers : - objectbucket.io/finalizer labels : bucket-provisioner : rook-ceph.ceph.rook.io-bucket name : ceph-delete-bucket namespace : rook-ceph ownerReferences : - apiVersion : objectbucket.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ObjectBucketClaim name : ceph-delete-bucket uid : a8c69ebc-1e4d-477c-97e7-479b532962b3 resourceVersion : \"1282724\" uid : 26786f4b-9371-46fa-8ca9-f470e5e92cb2 \u62ff\u5230secrets $ k get secrets ceph-delete-bucket -o yaml apiVersion : v1 data : AWS_ACCESS_KEY_ID : Rk9JSjxxBJNlg0NDVNUVVMVkpGMzc= AWS_SECRET_ACCESS_KEY : xxxxxxxxxxxxxxxxxxxxxxxxx== kind : Secret metadata : creationTimestamp : \"2022-08-05T08:24:27Z\" finalizers : - objectbucket.io/finalizer labels : bucket-provisioner : rook-ceph.ceph.rook.io-bucket name : ceph-delete-bucket namespace : rook-ceph ownerReferences : - apiVersion : objectbucket.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ObjectBucketClaim name : ceph-delete-bucket uid : a8c69ebc-1e4d-477c-97e7-479b532962b3 resourceVersion : \"1282723\" uid : 1b0af759-7c7d-4fe4-9a80-ea2615fa8fef type : Opaque base64 \u89e3\u5bc6 $ echo Rk9JSjBJNlg0NDVNUVVMVkpGMzc = | base64 -d FOIJ0I6X4xxxxxxx45MQULVJF37% # beiyiwangdejiyi @ beiyiwangdejiyideMacBook-Pro in ~/note-work/hugo on git:main x [14:28:13] $ echo SVdjaElaeVdUbTNGNkRyZ29UcxxxxxxxUQ0R1gzOVlhczR4S1ZmWExERHNYeA == | base64 -d IWchxxxxxxxxxxxxxxxxxxxx% fio --name=sequential-read --directory=/config --rw=read --refill_buffers --bs=4K --size=200M root@nginx-run-685fdf6467-mdl9v:/# fio --name = sequential-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M sequential-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-read: Laying out IO file ( 1 file / 200MiB ) sequential-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 723 : Wed Aug 10 06 :28:37 2022 read: IOPS = 98 .8k, BW = 386MiB/s ( 405MB/s )( 200MiB/518msec ) clat ( nsec ) : min = 378 , max = 86956k, avg = 9833 .73, stdev = 534902 .03 lat ( nsec ) : min = 411 , max = 86956k, avg = 9868 .39, stdev = 534902 .42 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 486 ] , 10 .00th =[ 532 ] , | 20 .00th =[ 556 ] , 30 .00th =[ 580 ] , 40 .00th =[ 604 ] , | 50 .00th =[ 628 ] , 60 .00th =[ 644 ] , 70 .00th =[ 668 ] , | 80 .00th =[ 708 ] , 90 .00th =[ 804 ] , 95 .00th =[ 932 ] , | 99 .00th =[ 70144 ] , 99 .50th =[ 102912 ] , 99 .90th =[ 456704 ] , | 99 .95th =[ 1253376 ] , 99 .99th =[ 26083328 ] bw ( KiB/s ) : min = 401376 , max = 401376 , per = 100 .00%, avg = 401376 .00, stdev = 0 .00, samples = 1 iops : min = 100344 , max = 100344 , avg = 100344 .00, stdev = 0 .00, samples = 1 lat ( nsec ) : 500 = 5 .72%, 750 = 80 .66%, 1000 = 9 .78% lat ( usec ) : 2 = 1 .74%, 4 = 0 .06%, 10 = 0 .17%, 20 = 0 .06%, 50 = 0 .11% lat ( usec ) : 100 = 1 .17%, 250 = 0 .37%, 500 = 0 .07%, 750 = 0 .02%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .02%, 4 = 0 .01%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01% cpu : usr = 3 .29%, sys = 17 .02%, ctx = 571 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 386MiB/s ( 405MB/s ) , 386MiB/s-386MiB/s ( 405MB/s-405MB/s ) , io = 200MiB ( 210MB ) , run = 518 -518msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M sequential-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 729 : Wed Aug 10 06 :30:48 2022 read: IOPS = 344k, BW = 1342MiB/s ( 1407MB/s )( 200MiB/149msec ) clat ( nsec ) : min = 375 , max = 7097 .8k, avg = 2339 .11, stdev = 39079 .52 lat ( nsec ) : min = 406 , max = 7097 .8k, avg = 2372 .97, stdev = 39080 .14 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 524 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 588 ] , 40 .00th =[ 612 ] , | 50 .00th =[ 628 ] , 60 .00th =[ 644 ] , 70 .00th =[ 668 ] , | 80 .00th =[ 700 ] , 90 .00th =[ 748 ] , 95 .00th =[ 868 ] , | 99 .00th =[ 67072 ] , 99 .50th =[ 73216 ] , 99 .90th =[ 114176 ] , | 99 .95th =[ 156672 ] , 99 .99th =[ 1122304 ] lat ( nsec ) : 500 = 2 .29%, 750 = 87 .79%, 1000 = 7 .05% lat ( usec ) : 2 = 0 .96%, 4 = 0 .01%, 10 = 0 .15%, 20 = 0 .04%, 50 = 0 .11% lat ( usec ) : 100 = 1 .42%, 250 = 0 .15%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2 = 0 .02%, 4 = 0 .01%, 10 = 0 .01% cpu : usr = 25 .68%, sys = 49 .32%, ctx = 335 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 1342MiB/s ( 1407MB/s ) , 1342MiB/s-1342MiB/s ( 1407MB/s-1407MB/s ) , io = 200MiB ( 210MB ) , run = 149 -149msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = big-file-multi-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.25 Starting 6 processes big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) big-file-multi-read: Laying out IO file ( 1 file / 200MiB ) Jobs: 2 ( f = 2 ) : [ _ ( 4 ) ,R ( 2 )][ 100 .0% ][ r = 264MiB/s ][ r = 67 .7k IOPS ][ eta 00m:00s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 732 : Wed Aug 10 06 :32:40 2022 read: IOPS = 11 .1k, BW = 43 .5MiB/s ( 45 .6MB/s )( 200MiB/4602msec ) clat ( nsec ) : min = 377 , max = 522247k, avg = 89494 .70, stdev = 4682750 .76 lat ( nsec ) : min = 408 , max = 522247k, avg = 89553 .19, stdev = 4682751 .34 clat percentiles ( nsec ) : | 1 .00th =[ 414 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 692 ] , 60 .00th =[ 732 ] , 70 .00th =[ 796 ] , | 80 .00th =[ 884 ] , 90 .00th =[ 1020 ] , 95 .00th =[ 1192 ] , | 99 .00th =[ 83456 ] , 99 .50th =[ 218112 ] , 99 .90th =[ 5144576 ] , | 99 .95th =[ 20578304 ] , 99 .99th =[ 240123904 ] bw ( KiB/s ) : min = 14080 , max = 90112 , per = 18 .59%, avg = 45625 .50, stdev = 27571 .34, samples = 8 iops : min = 3520 , max = 22528 , avg = 11406 .37, stdev = 6892 .84, samples = 8 lat ( nsec ) : 500 = 3 .47%, 750 = 60 .05%, 1000 = 25 .67% lat ( usec ) : 2 = 8 .49%, 4 = 0 .21%, 10 = 0 .15%, 20 = 0 .08%, 50 = 0 .07% lat ( usec ) : 100 = 1 .00%, 250 = 0 .33%, 500 = 0 .14%, 750 = 0 .07%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .05%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .02%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .59%, sys = 2 .00%, ctx = 671 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 733 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .7k, BW = 41 .9MiB/s ( 43 .9MB/s )( 200MiB/4776msec ) clat ( nsec ) : min = 376 , max = 734234k, avg = 92901 .06, stdev = 5934361 .60 lat ( nsec ) : min = 411 , max = 734234k, avg = 92951 .67, stdev = 5934362 .28 clat percentiles ( nsec ) : | 1 .00th =[ 402 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 588 ] , 30 .00th =[ 636 ] , 40 .00th =[ 684 ] , | 50 .00th =[ 732 ] , 60 .00th =[ 788 ] , 70 .00th =[ 860 ] , | 80 .00th =[ 940 ] , 90 .00th =[ 1080 ] , 95 .00th =[ 1272 ] , | 99 .00th =[ 91648 ] , 99 .50th =[ 193536 ] , 99 .90th =[ 3981312 ] , | 99 .95th =[ 27131904 ] , 99 .99th =[ 233832448 ] bw ( KiB/s ) : min = 8192 , max = 98304 , per = 19 .42%, avg = 47655 .75, stdev = 31431 .05, samples = 8 iops : min = 2048 , max = 24576 , avg = 11913 .88, stdev = 7857 .79, samples = 8 lat ( nsec ) : 500 = 3 .87%, 750 = 50 .45%, 1000 = 31 .27% lat ( usec ) : 2 = 12 .03%, 4 = 0 .18%, 10 = 0 .15%, 20 = 0 .07%, 50 = 0 .06% lat ( usec ) : 100 = 1 .02%, 250 = 0 .48%, 500 = 0 .15%, 750 = 0 .05%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .05%, 4 = 0 .02%, 10 = 0 .03%, 20 = 0 .02%, 50 = 0 .02% lat ( msec ) : 100 = 0 .02%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .44%, sys = 2 .07%, ctx = 845 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 734 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .9k, BW = 42 .6MiB/s ( 44 .7MB/s )( 200MiB/4696msec ) clat ( nsec ) : min = 379 , max = 607583k, avg = 91313 .18, stdev = 4982310 .93 lat ( nsec ) : min = 412 , max = 607583k, avg = 91361 .07, stdev = 4982311 .06 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 516 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 700 ] , 60 .00th =[ 740 ] , 70 .00th =[ 804 ] , | 80 .00th =[ 900 ] , 90 .00th =[ 1048 ] , 95 .00th =[ 1240 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 130560 ] , 99 .90th =[ 4882432 ] , | 99 .95th =[ 14483456 ] , 99 .99th =[ 254803968 ] bw ( KiB/s ) : min = 7680 , max = 90112 , per = 17 .01%, avg = 41739 .89, stdev = 24407 .57, samples = 9 iops : min = 1920 , max = 22528 , avg = 10434 .89, stdev = 6101 .90, samples = 9 lat ( nsec ) : 500 = 3 .93%, 750 = 58 .07%, 1000 = 25 .64% lat ( usec ) : 2 = 10 .13%, 4 = 0 .22%, 10 = 0 .13%, 20 = 0 .04%, 50 = 0 .08% lat ( usec ) : 100 = 1 .10%, 250 = 0 .34%, 500 = 0 .08%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .04%, 4 = 0 .03%, 10 = 0 .04%, 20 = 0 .02%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .72%, sys = 1 .81%, ctx = 502 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 735 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .6k, BW = 41 .5MiB/s ( 43 .5MB/s )( 200MiB/4822msec ) clat ( nsec ) : min = 374 , max = 700599k, avg = 93757 .53, stdev = 5099889 .71 lat ( nsec ) : min = 413 , max = 700599k, avg = 93803 .83, stdev = 5099890 .00 clat percentiles ( nsec ) : | 1 .00th =[ 430 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 620 ] , 40 .00th =[ 660 ] , | 50 .00th =[ 692 ] , 60 .00th =[ 732 ] , 70 .00th =[ 804 ] , | 80 .00th =[ 900 ] , 90 .00th =[ 1048 ] , 95 .00th =[ 1256 ] , | 99 .00th =[ 91648 ] , 99 .50th =[ 226304 ] , 99 .90th =[ 5931008 ] , | 99 .95th =[ 24248320 ] , 99 .99th =[ 235929600 ] bw ( KiB/s ) : min = 6520 , max = 65536 , per = 15 .07%, avg = 36989 .89, stdev = 18379 .13, samples = 9 iops : min = 1630 , max = 16384 , avg = 9247 .44, stdev = 4594 .77, samples = 9 lat ( nsec ) : 500 = 3 .74%, 750 = 59 .39%, 1000 = 24 .25% lat ( usec ) : 2 = 10 .19%, 4 = 0 .22%, 10 = 0 .18%, 20 = 0 .08%, 50 = 0 .08% lat ( usec ) : 100 = 0 .96%, 250 = 0 .43%, 500 = 0 .14%, 750 = 0 .07%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .06%, 20 = 0 .02%, 50 = 0 .02% lat ( msec ) : 100 = 0 .01%, 250 = 0 .02%, 500 = 0 .01%, 750 = 0 .01% cpu : usr = 0 .21%, sys = 2 .24%, ctx = 874 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 736 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .2k, BW = 39 .9MiB/s ( 41 .9MB/s )( 200MiB/5008msec ) clat ( nsec ) : min = 377 , max = 806541k, avg = 97234 .58, stdev = 6320832 .41 lat ( nsec ) : min = 414 , max = 806541k, avg = 97345 .92, stdev = 6320844 .03 clat percentiles ( nsec ) : | 1 .00th =[ 402 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 612 ] , 40 .00th =[ 652 ] , | 50 .00th =[ 684 ] , 60 .00th =[ 724 ] , 70 .00th =[ 772 ] , | 80 .00th =[ 868 ] , 90 .00th =[ 1032 ] , 95 .00th =[ 1240 ] , | 99 .00th =[ 80384 ] , 99 .50th =[ 154624 ] , 99 .90th =[ 5275648 ] , | 99 .95th =[ 20054016 ] , 99 .99th =[ 200278016 ] bw ( KiB/s ) : min = 8192 , max = 49152 , per = 12 .40%, avg = 30434 .00, stdev = 15445 .75, samples = 9 iops : min = 2048 , max = 12288 , avg = 7608 .44, stdev = 3861 .51, samples = 9 lat ( nsec ) : 500 = 3 .77%, 750 = 62 .98%, 1000 = 22 .07% lat ( usec ) : 2 = 8 .67%, 4 = 0 .18%, 10 = 0 .26%, 20 = 0 .12%, 50 = 0 .12% lat ( usec ) : 100 = 1 .05%, 250 = 0 .40%, 500 = 0 .11%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .05%, 4 = 0 .04%, 10 = 0 .03%, 20 = 0 .03%, 50 = 0 .02% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .46%, sys = 1 .96%, ctx = 787 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 737 : Wed Aug 10 06 :32:40 2022 read: IOPS = 10 .3k, BW = 40 .2MiB/s ( 42 .1MB/s )( 200MiB/4977msec ) clat ( nsec ) : min = 378 , max = 894860k, avg = 96613 .11, stdev = 5799729 .12 lat ( nsec ) : min = 413 , max = 894860k, avg = 96658 .78, stdev = 5799729 .19 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 506 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 612 ] , 40 .00th =[ 644 ] , | 50 .00th =[ 676 ] , 60 .00th =[ 716 ] , 70 .00th =[ 764 ] , | 80 .00th =[ 852 ] , 90 .00th =[ 988 ] , 95 .00th =[ 1176 ] , | 99 .00th =[ 87552 ] , 99 .50th =[ 216064 ] , 99 .90th =[ 6848512 ] , | 99 .95th =[ 31064064 ] , 99 .99th =[ 231735296 ] bw ( KiB/s ) : min = 16929 , max = 69632 , per = 14 .42%, avg = 35383 .25, stdev = 17459 .47, samples = 8 iops : min = 4232 , max = 17408 , avg = 8845 .75, stdev = 4364 .90, samples = 8 lat ( nsec ) : 500 = 4 .66%, 750 = 63 .16%, 1000 = 22 .55% lat ( usec ) : 2 = 7 .10%, 4 = 0 .20%, 10 = 0 .27%, 20 = 0 .09%, 50 = 0 .11% lat ( usec ) : 100 = 0 .99%, 250 = 0 .44%, 500 = 0 .12%, 750 = 0 .07%, 1000 = 0 .04% lat ( msec ) : 2 = 0 .06%, 4 = 0 .04%, 10 = 0 .03%, 20 = 0 .03%, 50 = 0 .01% lat ( msec ) : 100 = 0 .02%, 250 = 0 .02%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .32%, sys = 2 .05%, ctx = 1006 , majf = 0 , minf = 17 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 240MiB/s ( 251MB/s ) , 39 .9MiB/s-43.5MiB/s ( 41 .9MB/s-45.6MB/s ) , io = 1200MiB ( 1258MB ) , run = 4602 -5008msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = big-file-multi-read --directory = /config --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.25 Starting 6 processes Jobs: 3 ( f = 3 ) : [ _ ( 1 ) ,R ( 1 ) ,_ ( 1 ) ,R ( 1 ) ,_ ( 1 ) ,R ( 1 )][ 80 .0% ][ r = 172MiB/s ][ r = 44 .1k IOPS ][ eta 00m:02s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 740 : Wed Aug 10 06 :34:00 2022 read: IOPS = 8276 , BW = 32 .3MiB/s ( 33 .9MB/s )( 200MiB/6186msec ) clat ( nsec ) : min = 378 , max = 805881k, avg = 120250 .60, stdev = 7449083 .91 lat ( nsec ) : min = 410 , max = 805881k, avg = 120301 .98, stdev = 7449084 .14 clat percentiles ( nsec ) : | 1 .00th =[ 422 ] , 5 .00th =[ 532 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 580 ] , 30 .00th =[ 612 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 660 ] , 60 .00th =[ 684 ] , 70 .00th =[ 716 ] , | 80 .00th =[ 748 ] , 90 .00th =[ 860 ] , 95 .00th =[ 996 ] , | 99 .00th =[ 77312 ] , 99 .50th =[ 132096 ] , 99 .90th =[ 1318912 ] , | 99 .95th =[ 10289152 ] , 99 .99th =[ 434110464 ] bw ( KiB/s ) : min = 8192 , max = 65536 , per = 23 .93%, avg = 35045 .82, stdev = 25507 .11, samples = 11 iops : min = 2048 , max = 16384 , avg = 8761 .45, stdev = 6376 .78, samples = 11 lat ( nsec ) : 500 = 2 .40%, 750 = 77 .33%, 1000 = 15 .36% lat ( usec ) : 2 = 2 .64%, 4 = 0 .06%, 10 = 0 .18%, 20 = 0 .11%, 50 = 0 .13% lat ( usec ) : 100 = 1 .11%, 250 = 0 .39%, 500 = 0 .09%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .03%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% cpu : usr = 0 .34%, sys = 1 .62%, ctx = 845 , majf = 0 , minf = 14 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 741 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6102 , BW = 23 .8MiB/s ( 24 .0MB/s )( 200MiB/8390msec ) clat ( nsec ) : min = 379 , max = 1190 .5M, avg = 162758 .58, stdev = 11051920 .43 lat ( nsec ) : min = 413 , max = 1190 .5M, avg = 162807 .90, stdev = 11051920 .69 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 524 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 604 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 668 ] , 60 .00th =[ 700 ] , 70 .00th =[ 724 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1004 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 156672 ] , 99 .90th =[ 1073152 ] , | 99 .95th =[ 5275648 ] , 99 .99th =[ 616562688 ] bw ( KiB/s ) : min = 512 , max = 73728 , per = 20 .69%, avg = 30307 .20, stdev = 21673 .33, samples = 10 iops : min = 128 , max = 18432 , avg = 7576 .80, stdev = 5418 .33, samples = 10 lat ( nsec ) : 500 = 2 .76%, 750 = 73 .76%, 1000 = 18 .35% lat ( usec ) : 2 = 2 .79%, 4 = 0 .04%, 10 = 0 .22%, 20 = 0 .13%, 50 = 0 .14% lat ( usec ) : 100 = 1 .05%, 250 = 0 .42%, 500 = 0 .14%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .02%, 20 = 0 .01%, 100 = 0 .01% lat ( msec ) : 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .33%, sys = 1 .10%, ctx = 982 , majf = 0 , minf = 16 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 742 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6906 , BW = 26 .0MiB/s ( 28 .3MB/s )( 200MiB/7413msec ) clat ( nsec ) : min = 380 , max = 1034 .3M, avg = 144218 .03, stdev = 9148025 .05 lat ( nsec ) : min = 414 , max = 1034 .3M, avg = 144254 .80, stdev = 9148025 .00 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 524 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 596 ] , 40 .00th =[ 620 ] , | 50 .00th =[ 652 ] , 60 .00th =[ 676 ] , 70 .00th =[ 708 ] , | 80 .00th =[ 748 ] , 90 .00th =[ 860 ] , 95 .00th =[ 988 ] , | 99 .00th =[ 78336 ] , 99 .50th =[ 146432 ] , 99 .90th =[ 1253376 ] , | 99 .95th =[ 4620288 ] , 99 .99th =[ 522190848 ] bw ( KiB/s ) : min = 16384 , max = 73728 , per = 26 .85%, avg = 39318 .40, stdev = 23491 .33, samples = 10 iops : min = 4096 , max = 18432 , avg = 9829 .60, stdev = 5872 .83, samples = 10 lat ( nsec ) : 500 = 3 .29%, 750 = 76 .66%, 1000 = 15 .22% lat ( usec ) : 2 = 2 .43%, 4 = 0 .10%, 10 = 0 .23%, 20 = 0 .12%, 50 = 0 .12% lat ( usec ) : 100 = 1 .13%, 250 = 0 .37%, 500 = 0 .13%, 750 = 0 .05%, 1000 = 0 .03% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2000 = 0 .01% cpu : usr = 0 .32%, sys = 1 .32%, ctx = 864 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 743 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6106 , BW = 23 .9MiB/s ( 25 .0MB/s )( 200MiB/8385msec ) clat ( nsec ) : min = 380 , max = 1507 .9M, avg = 162772 .24, stdev = 13174473 .96 lat ( nsec ) : min = 414 , max = 1507 .9M, avg = 162810 .08, stdev = 13174473 .94 clat percentiles ( nsec ) : | 1 .00th =[ 398 ] , 5 .00th =[ 510 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 604 ] , 40 .00th =[ 636 ] , | 50 .00th =[ 668 ] , 60 .00th =[ 692 ] , 70 .00th =[ 724 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1012 ] , | 99 .00th =[ 79360 ] , 99 .50th =[ 136192 ] , 99 .90th =[ 897024 ] , | 99 .95th =[ 2506752 ] , 99 .99th =[ 434110464 ] bw ( KiB/s ) : min = 8 , max = 81920 , per = 20 .70%, avg = 30310 .40, stdev = 22461 .38, samples = 10 iops : min = 2 , max = 20480 , avg = 7577 .60, stdev = 5615 .35, samples = 10 lat ( nsec ) : 500 = 4 .29%, 750 = 73 .14%, 1000 = 17 .30% lat ( usec ) : 2 = 2 .94%, 4 = 0 .04%, 10 = 0 .22%, 20 = 0 .07%, 50 = 0 .19% lat ( usec ) : 100 = 1 .10%, 250 = 0 .44%, 500 = 0 .11%, 750 = 0 .05%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .03%, 4 = 0 .01%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .05%, sys = 1 .40%, ctx = 993 , majf = 0 , minf = 14 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 744 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6911 , BW = 26 .0MiB/s ( 28 .3MB/s )( 200MiB/7408msec ) clat ( nsec ) : min = 381 , max = 1179 .3M, avg = 143994 .58, stdev = 11079777 .48 lat ( nsec ) : min = 413 , max = 1179 .3M, avg = 144029 .70, stdev = 11079777 .45 clat percentiles ( nsec ) : | 1 .00th =[ 406 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 580 ] , 40 .00th =[ 612 ] , | 50 .00th =[ 636 ] , 60 .00th =[ 668 ] , 70 .00th =[ 692 ] , | 80 .00th =[ 732 ] , 90 .00th =[ 836 ] , 95 .00th =[ 956 ] , | 99 .00th =[ 76288 ] , 99 .50th =[ 111104 ] , 99 .90th =[ 995328 ] , | 99 .95th =[ 3227648 ] , 99 .99th =[ 742391808 ] bw ( KiB/s ) : min = 5040 , max = 73728 , per = 22 .93%, avg = 33587 .20, stdev = 27492 .28, samples = 10 iops : min = 1260 , max = 18432 , avg = 8396 .80, stdev = 6873 .07, samples = 10 lat ( nsec ) : 500 = 3 .81%, 750 = 78 .93%, 1000 = 13 .08% lat ( usec ) : 2 = 2 .02%, 4 = 0 .02%, 10 = 0 .21%, 20 = 0 .07%, 50 = 0 .12% lat ( usec ) : 100 = 1 .15%, 250 = 0 .36%, 500 = 0 .07%, 750 = 0 .04%, 1000 = 0 .02% lat ( msec ) : 2 = 0 .04%, 4 = 0 .02%, 10 = 0 .01%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01%, 2000 = 0 .01% cpu : usr = 0 .26%, sys = 1 .35%, ctx = 724 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 745 : Wed Aug 10 06 :34:00 2022 read: IOPS = 6238 , BW = 24 .4MiB/s ( 25 .6MB/s )( 200MiB/8207msec ) clat ( nsec ) : min = 379 , max = 1170 .8M, avg = 159639 .78, stdev = 10672683 .50 lat ( nsec ) : min = 413 , max = 1170 .8M, avg = 159675 .27, stdev = 10672683 .47 clat percentiles ( nsec ) : | 1 .00th =[ 410 ] , 5 .00th =[ 516 ] , 10 .00th =[ 540 ] , | 20 .00th =[ 572 ] , 30 .00th =[ 596 ] , 40 .00th =[ 628 ] , | 50 .00th =[ 652 ] , 60 .00th =[ 684 ] , 70 .00th =[ 716 ] , | 80 .00th =[ 764 ] , 90 .00th =[ 876 ] , 95 .00th =[ 1012 ] , | 99 .00th =[ 77312 ] , 99 .50th =[ 156672 ] , 99 .90th =[ 1810432 ] , | 99 .95th =[ 5865472 ] , 99 .99th =[ 616562688 ] bw ( KiB/s ) : min = 6400 , max = 74752 , per = 18 .50%, avg = 27096 .62, stdev = 22310 .47, samples = 13 iops : min = 1600 , max = 18688 , avg = 6774 .15, stdev = 5577 .62, samples = 13 lat ( nsec ) : 500 = 4 .00%, 750 = 74 .22%, 1000 = 16 .52% lat ( usec ) : 2 = 3 .01%, 4 = 0 .05%, 10 = 0 .19%, 20 = 0 .07%, 50 = 0 .11% lat ( usec ) : 100 = 1 .06%, 250 = 0 .40%, 500 = 0 .14%, 750 = 0 .05%, 1000 = 0 .05% lat ( msec ) : 2 = 0 .04%, 4 = 0 .03%, 10 = 0 .03%, 20 = 0 .01%, 50 = 0 .01% lat ( msec ) : 100 = 0 .01%, 250 = 0 .01%, 500 = 0 .01%, 750 = 0 .01%, 1000 = 0 .01% lat ( msec ) : 2000 = 0 .01% cpu : usr = 0 .26%, sys = 1 .22%, ctx = 949 , majf = 0 , minf = 15 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 51200 ,0,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : READ: bw = 143MiB/s ( 150MB/s ) , 23 .8MiB/s-32.3MiB/s ( 24 .0MB/s-33.9MB/s ) , io = 1200MiB ( 1258MB ) , run = 6186 -8390msec fio --name=sequential-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --end_fsync=1 fio --name=big-file-multi-read --directory=$PWD --rw=read --refill_buffers --bs=4K --size=200M --numjobs=6 fio --name=sequential-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --end_fsync=1 root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-write --directory = /config --rw = write --refill_buffers --bs = 4K --size = 200M --end_fsync = 1 sequential-write: ( g = 0 ) : rw = write, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process sequential-write: Laying out IO file ( 1 file / 200MiB ) Jobs: 1 ( f = 1 ) sequential-write: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 756 : Wed Aug 10 06 :39:40 2022 write: IOPS = 33 .6k, BW = 131MiB/s ( 138MB/s )( 200MiB/1525msec ) ; 0 zone resets clat ( usec ) : min = 7 , max = 7420 , avg = 27 .69, stdev = 125 .85 lat ( usec ) : min = 7 , max = 7420 , avg = 27 .76, stdev = 125 .85 clat percentiles ( usec ) : | 1 .00th =[ 8 ] , 5 .00th =[ 9 ] , 10 .00th =[ 11 ] , 20 .00th =[ 12 ] , | 30 .00th =[ 20 ] , 40 .00th =[ 21 ] , 50 .00th =[ 22 ] , 60 .00th =[ 22 ] , | 70 .00th =[ 23 ] , 80 .00th =[ 24 ] , 90 .00th =[ 28 ] , 95 .00th =[ 37 ] , | 99 .00th =[ 118 ] , 99 .50th =[ 285 ] , 99 .90th =[ 1860 ] , 99 .95th =[ 3097 ] , | 99 .99th =[ 4752 ] bw ( KiB/s ) : min = 132286 , max = 138088 , per = 100 .00%, avg = 135187 .00, stdev = 4102 .63, samples = 2 iops : min = 33071 , max = 34522 , avg = 33796 .50, stdev = 1026 .01, samples = 2 lat ( usec ) : 10 = 9 .54%, 20 = 24 .43%, 50 = 63 .08%, 100 = 1 .75%, 250 = 0 .66% lat ( usec ) : 500 = 0 .22%, 750 = 0 .09%, 1000 = 0 .05% lat ( msec ) : 2 = 0 .10%, 4 = 0 .07%, 10 = 0 .03% cpu : usr = 9 .84%, sys = 31 .04%, ctx = 51905 , majf = 0 , minf = 12 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 0 ,51200,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : WRITE: bw = 131MiB/s ( 138MB/s ) , 131MiB/s-131MiB/s ( 138MB/s-138MB/s ) , io = 200MiB ( 210MB ) , run = 1525 -1525msec root@nginx-run-685fdf6467-mdl9v:/config# fio --name = sequential-write --directory = /config --rw = write --refill_buffers --bs = 4K --size = 200M --end_fsync = 1 sequential-write: ( g = 0 ) : rw = write, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 fio-3.25 Starting 1 process Jobs: 1 ( f = 1 ) sequential-write: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 759 : Wed Aug 10 06 :41:20 2022 write: IOPS = 31 .3k, BW = 122MiB/s ( 128MB/s )( 200MiB/1637msec ) ; 0 zone resets clat ( usec ) : min = 7 , max = 9234 , avg = 30 .16, stdev = 137 .54 lat ( usec ) : min = 7 , max = 9234 , avg = 30 .21, stdev = 137 .54 clat percentiles ( usec ) : | 1 .00th =[ 8 ] , 5 .00th =[ 9 ] , 10 .00th =[ 11 ] , 20 .00th =[ 18 ] , | 30 .00th =[ 20 ] , 40 .00th =[ 21 ] , 50 .00th =[ 22 ] , 60 .00th =[ 22 ] , | 70 .00th =[ 23 ] , 80 .00th =[ 24 ] , 90 .00th =[ 29 ] , 95 .00th =[ 41 ] , | 99 .00th =[ 147 ] , 99 .50th =[ 379 ] , 99 .90th =[ 2311 ] , 99 .95th =[ 3064 ] , | 99 .99th =[ 4490 ] bw ( KiB/s ) : min = 119544 , max = 132640 , per = 100 .00%, avg = 128018 .67, stdev = 7349 .32, samples = 3 iops : min = 29886 , max = 33160 , avg = 32004 .67, stdev = 1837 .33, samples = 3 lat ( usec ) : 10 = 7 .32%, 20 = 25 .16%, 50 = 63 .95%, 100 = 2 .08%, 250 = 0 .85% lat ( usec ) : 500 = 0 .23%, 750 = 0 .09%, 1000 = 0 .08% lat ( msec ) : 2 = 0 .12%, 4 = 0 .11%, 10 = 0 .02% cpu : usr = 7 .21%, sys = 32 .64%, ctx = 51971 , majf = 0 , minf = 13 IO depths : 1 = 100 .0%, 2 = 0 .0%, 4 = 0 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, > = 64 = 0 .0% submit : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% complete : 0 = 0 .0%, 4 = 100 .0%, 8 = 0 .0%, 16 = 0 .0%, 32 = 0 .0%, 64 = 0 .0%, > = 64 = 0 .0% issued rwts: total = 0 ,51200,0,0 short = 0 ,0,0,0 dropped = 0 ,0,0,0 latency : target = 0 , window = 0 , percentile = 100 .00%, depth = 1 Run status group 0 ( all jobs ) : WRITE: bw = 122MiB/s ( 128MB/s ) , 122MiB/s-122MiB/s ( 128MB/s-128MB/s ) , io = 200MiB ( 210MB ) , run = 1637 -1637msec fio --name=big-file-multi-write --directory=/config --rw=write --refill_buffers --bs=4K --size=200M --numjobs=6 --end_fsync=1 fio -filename=/config/fio.img -direct=1 -iodepth 32 -thread -rw=randread -ioengine=libaio -bs=4k -size=200m -numjobs=2 -runtime=60 -group_reporting -name=mytest \u56fa\u6001\u5bbf\u4e3b\u673a\uff1a [ ucloud ] root@node1:/var/jfsCache# fio --name = big-file-multi-read --directory = $PWD --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.16 Starting 6 processes Jobs: 6 ( f = 6 ) : [ R ( 6 )][ 88 .9% ][ r = 130MiB/s ][ r = 33 .2k IOPS ][ eta 00m:01s ] big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 225237 : Fri Aug 12 14 :09:04 2022 read: IOPS = 5925 , BW = 23 .1MiB/s ( 24 .3MB/s )( 200MiB/8641msec ) clat ( nsec ) : min = 434 , max = 21757k, avg = 168221 .11, stdev = 1662876 .10 lat ( nsec ) : min = 471 , max = 21757k, avg = 168260 .51, stdev = 1662876 .63 clat percentiles ( nsec ) : | 1 .00th =[ 524 ] , 5 .00th =[ 540 ] , 10 .00th =[ 548 ] , | 20 .00th =[ 564 ] , 30 .00th =[ 572 ] , 40 .00th =[ 580 ] , | 50 .00th =[ 596 ] , 60 .00th =[ 612 ] , 70 .00th =[ 628 ] , | 80 .00th =[ 660 ] , 90 .00th =[ 732 ] , 95 .00th =[ 884 ] , | 99 .00th =[ 3948544 ] , 99 .50th =[ 19005440 ] , 99 .90th =[ 20054016 ] , | 99 .95th =[ 20054016 ] , 99 .99th =[ 20054016 ] \u5185\u5b58\u5bbf\u4e3b\u673a\uff1a [ ucloud ] root@node1:/var/jfsCache# fio --name = big-file-multi-read --directory = $PWD --rw = read --refill_buffers --bs = 4K --size = 200M --numjobs = 6 big-file-multi-read: ( g = 0 ) : rw = read, bs =( R ) 4096B-4096B, ( W ) 4096B-4096B, ( T ) 4096B-4096B, ioengine = psync, iodepth = 1 ... fio-3.16 Starting 6 processes big-file-multi-read: ( groupid = 0 , jobs = 1 ) : err = 0 : pid = 12095 : Fri Aug 12 15 :05:27 2022 read: IOPS = 966k, BW = 3774MiB/s ( 3957MB/s )( 200MiB/53msec ) clat ( nsec ) : min = 520 , max = 221610 , avg = 757 .38, stdev = 2561 .09 lat ( nsec ) : min = 553 , max = 221646 , avg = 792 .50, stdev = 2561 .18 clat percentiles ( nsec ) : | 1 .00th =[ 540 ] , 5 .00th =[ 556 ] , 10 .00th =[ 556 ] , 20 .00th =[ 564 ] , | 30 .00th =[ 572 ] , 40 .00th =[ 580 ] , 50 .00th =[ 596 ] , 60 .00th =[ 612 ] , | 70 .00th =[ 644 ] , 80 .00th =[ 724 ] , 90 .00th =[ 908 ] , 95 .00th =[ 940 ] , | 99 .00th =[ 3344 ] , 99 .50th =[ 3728 ] , 99 .90th =[ 19072 ] , 99 .95th =[ 43264 ] , | 99 .99th =[ 115200 ] fio --name=small-file-multi-read \\ --directory=/config \\ --rw=read --file_service_type=sequential \\ --bs=4k --filesize=4k --nrfiles=500 \\ --numjobs=2","title":"\u5bb9\u5668\u8bbf\u95ee\u5bf9\u8c61\u5b58\u50a8"},{"location":"error/dev/","text":"Dev\u96c6\u7fa4\u95ee\u9898 \u00b6 rook-ceph\u96c6\u7fa4\u5d29\u6e83 \u73b0\u8c61: rook-ceph\u96c6\u7fa4\u9664\u4e86mon\uff0c\u6240\u6709pod\u7684\u72b6\u6001\u5904\u4e8eCrashLoopBackOff mgr \u65e0\u6cd5\u6b63\u5e38\u5de5\u4f5c operator\u7684log\u4e2d\u65e0\u660e\u663e\u62a5\u9519\uff0cceph-cluster-controller: failed to get ceph daemons versions, this typically happens during the first cluster initialization. failed to run 'ceph versions' mon \u88aboperator\u4e00\u5171\u8d77\u67654\u4e2adeploy \u9519\u8bef\u76f8\u4f3c\u5ea6: https://github.com/rook/rook/issues/6530 \u521d\u6b65\u6000\u7591\u662frook-ceph\u7684osd\u548c\u7cfb\u7edf\u78c1\u76d8\u4f7f\u7528\u5feb\u6ee1\u800c\u5bfc\u81f4\u7684\u96c6\u7fa4\u5d29\u6e83\uff0c\u53ea\u6709mon\u6b63\u5e38\uff0cmgr\u548cosd\u90fd\u5f02\u5e38 \u65e0\u6cd5\u6b63\u5e38running $ kubectl -n rook-ceph get pod -w ... rook-ceph-mgr-a-7fd6649d8c-jqvmv 0 /1 CrashLoopBackOff 35 20h rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:CrashLoopBackOff 1 6s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:2/4 2 18s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:Error 2 19s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:CrashLoopBackOff 2 31s \u9996\u5148\u9700\u8981\u5c06\u96c6\u7fa4\u6062\u590d\u5230\u6b63\u5e38\u7684\u4e00\u4e2a\u72b6\u6001\uff0c\u8fd9\u91cc\u6709\u4e2a\u95ee\u9898\u5c31\u662fmon\u4e00\u4e2a\u5904\u4e8e\u4e00\u4e2a4\u526f\u672c\u7684\u72b6\u6001,\u6709\u4e00\u4e2a\u526f\u672c\u72b6\u6001\u5f02\u5e38 \u67e5\u770b\u5f02\u5e38\u72b6\u6001\u4e0bmon\u7684configmap,\u8fd9\u9700\u8981\u5c06\u5f02\u5e38\u7684\u90a3\u4e2apod\u7684\u6240\u6709\u914d\u7f6e\u5220\u9664 $ kg configmap rook-ceph-mon-endpoints -o yaml apiVersion : v1 data : csi-cluster-config-json : '[{\"clusterID\":\"rook-ceph\",\"monitors\":[\"10.0.0.225:6789\",\"10.0.0.10:6789\",\"10.0.0.79:6789\",\"10.0.0.225:6789\"]}]' data : c=10.0.0.10:6789,a=10.0.0.79:6789,p=10.0.0.225:6789,q=10.0.0.225:6789 mapping : '{\"node\":{\"a\":{\"Name\":\"node1\",\"Hostname\":\"node1\",\"Address\":\"10.0.0.79\"},\"c\":{\"Name\":\"node0\",\"Hostname\":\"node0\",\"Address\":\"10.0.0.10\"},\"p\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"},\"q\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"}}}' maxMonId : \"16\" kind : ConfigMap metadata : creationTimestamp : \"2020-12-16T18:00:19Z\" name : rook-ceph-mon-endpoints namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"555335505\" uid : 1ee20194-f90e-4736-8d7f-89ac0314556c \u7559\u4e0b\u4e09\u4e2a\u6b63\u5e38\u7684mon $ k get configmap rook-ceph-mon-endpoints -o yaml apiVersion : v1 data : csi-cluster-config-json : '[{\"clusterID\":\"rook-ceph\",\"monitors\":[\"10.0.0.225:6789\",\"10.0.0.10:6789\",\"10.0.0.79:6789\"]}]' data : q=10.0.0.225:6789,c=10.0.0.10:6789,a=10.0.0.79:6789 mapping : '{\"node\":{\"a\":{\"Name\":\"node1\",\"Hostname\":\"node1\",\"Address\":\"10.0.0.79\"},\"c\":{\"Name\":\"node0\",\"Hostname\":\"node0\",\"Address\":\"10.0.0.10\"},\"q\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"}}}' maxMonId : \"16\" kind : ConfigMap metadata : creationTimestamp : \"2020-12-16T18:00:19Z\" name : rook-ceph-mon-endpoints namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"555840878\" uid : 1ee20194-f90e-4736-8d7f-89ac0314556c \u4fee\u6539\u5b8c\u6210\u53d1\u73b0mgr\u6b63\u5728\u6062\u590d\uff0c\u96c6\u7fa4\u7684\u72b6\u6001\u6162\u6162\u6062\u590d\u6b63\u5e38,\u4e00\u76f4\u7b49\u5230\u96c6\u7fa4\u6062\u590d\u6b63\u5e38\u3002\u8fd9\u65f6\u67e5\u770b\u96c6\u7fa4\u7684\u72b6\u6001 \u8fd8\u662f\u6709\u4e00\u4e9b\u5f02\u5e38\uff0c\u5927\u6982\u7684\u610f\u601d\u5c31\u662fmon-a\u6240\u5728\u7684\u673a\u5668\u7684\u7cfb\u7edf\u76d8\u5feb\u6ee1\u4e86 \u9700\u8981\u8fdb\u884c\u4e0b\u4e00\u6b65\uff0c\u6269\u5bb9\u7cfb\u7edf\u76d8\uff0c\u673a\u5668\u5728ucloud\u4e91\uff0c\u6240\u4ee5\u6211\u4eec\u5148\u5728ui\u754c\u9762\u8fdb\u884c\u6269\u5bb9\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003 Ucloud\u6269\u5bb9 Ubuntu\uff1a sudo apt-get install cloud-initramfs-growroot LANG=en_US.UTF-8 growpart /dev/vda 1 \u8fd9\u65f6\uff0c\u6211\u4eec\u518d\u8fdb\u884c\u67e5\u770b\u6211\u4eec\u7684ceph\u96c6\u7fa4 [ root@rook-ceph-tools-84fc455b76-5dlwr / ] # ceph -s cluster: id: fc55d844-ed6b-4c0b-9f0f-a6b453ffb9b6 health: HEALTH_WARN 1 pool ( s ) do not have an application enabled 2 pool ( s ) have no replicas configured services: mon: 3 daemons, quorum a,c,q ( age 20h ) mgr: a ( active, since 18h ) mds: myfs:1 { 0 = myfs-b = up:active } 1 up:standby-replay osd: 7 osds: 7 up ( since 18h ) , 7 in ( since 18h ) task status: scrub status: mds.myfs-a: idle mds.myfs-b: idle data: pools: 6 pools, 241 pgs objects: 369 .17k objects, 92 GiB usage: 181 GiB used, 259 GiB / 440 GiB avail pgs: 241 active+clean io: client: 3 .3 KiB/s rd, 9 .3 KiB/s wr, 3 op/s rd, 1 op/s wr","title":"Dev\u73af\u5883\u96c6\u7fa4"},{"location":"error/dev/#dev","text":"rook-ceph\u96c6\u7fa4\u5d29\u6e83 \u73b0\u8c61: rook-ceph\u96c6\u7fa4\u9664\u4e86mon\uff0c\u6240\u6709pod\u7684\u72b6\u6001\u5904\u4e8eCrashLoopBackOff mgr \u65e0\u6cd5\u6b63\u5e38\u5de5\u4f5c operator\u7684log\u4e2d\u65e0\u660e\u663e\u62a5\u9519\uff0cceph-cluster-controller: failed to get ceph daemons versions, this typically happens during the first cluster initialization. failed to run 'ceph versions' mon \u88aboperator\u4e00\u5171\u8d77\u67654\u4e2adeploy \u9519\u8bef\u76f8\u4f3c\u5ea6: https://github.com/rook/rook/issues/6530 \u521d\u6b65\u6000\u7591\u662frook-ceph\u7684osd\u548c\u7cfb\u7edf\u78c1\u76d8\u4f7f\u7528\u5feb\u6ee1\u800c\u5bfc\u81f4\u7684\u96c6\u7fa4\u5d29\u6e83\uff0c\u53ea\u6709mon\u6b63\u5e38\uff0cmgr\u548cosd\u90fd\u5f02\u5e38 \u65e0\u6cd5\u6b63\u5e38running $ kubectl -n rook-ceph get pod -w ... rook-ceph-mgr-a-7fd6649d8c-jqvmv 0 /1 CrashLoopBackOff 35 20h rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:CrashLoopBackOff 1 6s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:2/4 2 18s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:Error 2 19s rook-ceph-osd-0-58c8d8ccf8-96wtd 0 /1 Init:CrashLoopBackOff 2 31s \u9996\u5148\u9700\u8981\u5c06\u96c6\u7fa4\u6062\u590d\u5230\u6b63\u5e38\u7684\u4e00\u4e2a\u72b6\u6001\uff0c\u8fd9\u91cc\u6709\u4e2a\u95ee\u9898\u5c31\u662fmon\u4e00\u4e2a\u5904\u4e8e\u4e00\u4e2a4\u526f\u672c\u7684\u72b6\u6001,\u6709\u4e00\u4e2a\u526f\u672c\u72b6\u6001\u5f02\u5e38 \u67e5\u770b\u5f02\u5e38\u72b6\u6001\u4e0bmon\u7684configmap,\u8fd9\u9700\u8981\u5c06\u5f02\u5e38\u7684\u90a3\u4e2apod\u7684\u6240\u6709\u914d\u7f6e\u5220\u9664 $ kg configmap rook-ceph-mon-endpoints -o yaml apiVersion : v1 data : csi-cluster-config-json : '[{\"clusterID\":\"rook-ceph\",\"monitors\":[\"10.0.0.225:6789\",\"10.0.0.10:6789\",\"10.0.0.79:6789\",\"10.0.0.225:6789\"]}]' data : c=10.0.0.10:6789,a=10.0.0.79:6789,p=10.0.0.225:6789,q=10.0.0.225:6789 mapping : '{\"node\":{\"a\":{\"Name\":\"node1\",\"Hostname\":\"node1\",\"Address\":\"10.0.0.79\"},\"c\":{\"Name\":\"node0\",\"Hostname\":\"node0\",\"Address\":\"10.0.0.10\"},\"p\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"},\"q\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"}}}' maxMonId : \"16\" kind : ConfigMap metadata : creationTimestamp : \"2020-12-16T18:00:19Z\" name : rook-ceph-mon-endpoints namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"555335505\" uid : 1ee20194-f90e-4736-8d7f-89ac0314556c \u7559\u4e0b\u4e09\u4e2a\u6b63\u5e38\u7684mon $ k get configmap rook-ceph-mon-endpoints -o yaml apiVersion : v1 data : csi-cluster-config-json : '[{\"clusterID\":\"rook-ceph\",\"monitors\":[\"10.0.0.225:6789\",\"10.0.0.10:6789\",\"10.0.0.79:6789\"]}]' data : q=10.0.0.225:6789,c=10.0.0.10:6789,a=10.0.0.79:6789 mapping : '{\"node\":{\"a\":{\"Name\":\"node1\",\"Hostname\":\"node1\",\"Address\":\"10.0.0.79\"},\"c\":{\"Name\":\"node0\",\"Hostname\":\"node0\",\"Address\":\"10.0.0.10\"},\"q\":{\"Name\":\"master0\",\"Hostname\":\"master0\",\"Address\":\"10.0.0.225\"}}}' maxMonId : \"16\" kind : ConfigMap metadata : creationTimestamp : \"2020-12-16T18:00:19Z\" name : rook-ceph-mon-endpoints namespace : rook-ceph ownerReferences : - apiVersion : ceph.rook.io/v1 blockOwnerDeletion : true controller : true kind : CephCluster name : rook-ceph uid : ee10d125-4428-4e88-983a-53190bc3411c resourceVersion : \"555840878\" uid : 1ee20194-f90e-4736-8d7f-89ac0314556c \u4fee\u6539\u5b8c\u6210\u53d1\u73b0mgr\u6b63\u5728\u6062\u590d\uff0c\u96c6\u7fa4\u7684\u72b6\u6001\u6162\u6162\u6062\u590d\u6b63\u5e38,\u4e00\u76f4\u7b49\u5230\u96c6\u7fa4\u6062\u590d\u6b63\u5e38\u3002\u8fd9\u65f6\u67e5\u770b\u96c6\u7fa4\u7684\u72b6\u6001 \u8fd8\u662f\u6709\u4e00\u4e9b\u5f02\u5e38\uff0c\u5927\u6982\u7684\u610f\u601d\u5c31\u662fmon-a\u6240\u5728\u7684\u673a\u5668\u7684\u7cfb\u7edf\u76d8\u5feb\u6ee1\u4e86 \u9700\u8981\u8fdb\u884c\u4e0b\u4e00\u6b65\uff0c\u6269\u5bb9\u7cfb\u7edf\u76d8\uff0c\u673a\u5668\u5728ucloud\u4e91\uff0c\u6240\u4ee5\u6211\u4eec\u5148\u5728ui\u754c\u9762\u8fdb\u884c\u6269\u5bb9\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003 Ucloud\u6269\u5bb9 Ubuntu\uff1a sudo apt-get install cloud-initramfs-growroot LANG=en_US.UTF-8 growpart /dev/vda 1 \u8fd9\u65f6\uff0c\u6211\u4eec\u518d\u8fdb\u884c\u67e5\u770b\u6211\u4eec\u7684ceph\u96c6\u7fa4 [ root@rook-ceph-tools-84fc455b76-5dlwr / ] # ceph -s cluster: id: fc55d844-ed6b-4c0b-9f0f-a6b453ffb9b6 health: HEALTH_WARN 1 pool ( s ) do not have an application enabled 2 pool ( s ) have no replicas configured services: mon: 3 daemons, quorum a,c,q ( age 20h ) mgr: a ( active, since 18h ) mds: myfs:1 { 0 = myfs-b = up:active } 1 up:standby-replay osd: 7 osds: 7 up ( since 18h ) , 7 in ( since 18h ) task status: scrub status: mds.myfs-a: idle mds.myfs-b: idle data: pools: 6 pools, 241 pgs objects: 369 .17k objects, 92 GiB usage: 181 GiB used, 259 GiB / 440 GiB avail pgs: 241 active+clean io: client: 3 .3 KiB/s rd, 9 .3 KiB/s wr, 3 op/s rd, 1 op/s wr","title":"Dev\u96c6\u7fa4\u95ee\u9898"},{"location":"error/tjtu/","text":"\u5929\u6d25\u5927\u5b66\u96c6\u7fa4\u95ee\u9898 \u00b6 \u95ee\u9898\u590d\u73b0 \u4ece\u4e0b\u56fe\u53ef\u4ee5\u770b\u51fa\u6709\u5f88\u591a\u7684\u4efb\u52a1\u5904\u4e8e\u6570\u636e\u540c\u6b65\u5173\u95ed\u7684\u4e00\u4e2a\u72b6\u6001 \u95ee\u9898\u6392\u67e5 \u67e5\u770bk8s\u96c6\u7fa4\u7684\u72b6\u6001\uff0c\u53d1\u73b0\u4e00\u4e0bpod\u5904\u4e8e\u5f02\u5e38\u72b6\u6001\uff0c\u8fd9\u4e9b\u5f02\u5e38\u7684pod\u53ea\u80fd\u5168\u90e8\u5220\u9664\u91cd\u5efa \u9700\u8981\u67e5\u770b\u4e00\u4e0b\u5f02\u5e38pod\u7684\u8be6\u7ec6\u4fe1\u606f \u95ee\u9898\u51fa\u73b0 \u4ee5\u4e0a\u53ef\u4ee5\u770b\u5230pod\u5728\u521b\u5efa\u7f16\u53f7\u4e3a9\u7684gpu\u51fa\u73b0\u62a5\u9519\uff0c\u5bfc\u81f4\u8fd9\u6837\u7684\u60c5\u51b5\u53ef\u80fd\u5c31\u662fgpu\u51fa\u95ee\u9898\u4e86 \u63a5\u4e0b\u6765\u53ef\u4ee5\u68c0\u67e5\u8fd9\u4e2apod\u6240\u5728\u7684\u673a\u5668\u4e0a\u7684gpu\uff0c\u770b\u662f\u5426\u51fa\u73b0\u95ee\u9898 \u53ef\u4ee5\u901a\u8fc7 nvidia-smi -L \u547d\u4ee4\u6765\u67e5\u770b \u68c0\u67e5gpu \u51fa\u73b0\u4ee5\u4e0b\u60c5\u51b5\uff0c\u5c1d\u8bd5\u91cd\u542f\u770b\u770b\u662f\u5426\u80fd\u4fee\u590d \u5929\u6d25\u5927\u5b66\u96c6\u7fa4gpu\u786c\u4ef6\u635f\u574f GPU\u635f\u574f \u53ef\u4ee5\u901a\u8fc7nvidia-smi -L \u67e5\u770bgpu\u60c5\u51b5 nvidia-smi Unable to determine the device handle for GPU 0000 :89:00.0: Unknown Error \u611f\u89c9\u662f\u8fd9\u5757\u5361 0000:89:00.0 \u51fa\u95ee\u9898\u4e86\u3002\u7136\u540e\u53bb\u6267\u884c\u4e0b dmesg \u770b\u770b\u60c5\u51b5\uff1a $ dmesg -T [ Mon May 9 20 :37:33 2022 ] xhci_hcd 0000 :89:00.2: PCI post-resume error -19! [ Mon May 9 20 :37:33 2022 ] xhci_hcd 0000 :89:00.2: HC died ; cleaning up [ Mon May 9 20 :37:34 2022 ] nvidia-gpu 0000 :89:00.3: i2c timeout error ffffffff [ Mon May 9 20 :37:34 2022 ] ucsi_ccg 6 -0008: i2c_transfer failed -110 $ nvidia-smi drain -p 0000 :89:00.0 -m 1 Successfully set GPU 00000000 :89:00.0 drain state to: drainin \u5c4f\u853d\u5b8c\u6210\u8fd9\u53f0\u673a\u5668\uff0c\u9700\u8981\u8fdb\u884c\u91cd\u65b0\u542f\u52a8","title":"\u5929\u6d25\u96c6\u7fa4"},{"location":"error/tjtu/#_1","text":"\u95ee\u9898\u590d\u73b0 \u4ece\u4e0b\u56fe\u53ef\u4ee5\u770b\u51fa\u6709\u5f88\u591a\u7684\u4efb\u52a1\u5904\u4e8e\u6570\u636e\u540c\u6b65\u5173\u95ed\u7684\u4e00\u4e2a\u72b6\u6001 \u95ee\u9898\u6392\u67e5 \u67e5\u770bk8s\u96c6\u7fa4\u7684\u72b6\u6001\uff0c\u53d1\u73b0\u4e00\u4e0bpod\u5904\u4e8e\u5f02\u5e38\u72b6\u6001\uff0c\u8fd9\u4e9b\u5f02\u5e38\u7684pod\u53ea\u80fd\u5168\u90e8\u5220\u9664\u91cd\u5efa \u9700\u8981\u67e5\u770b\u4e00\u4e0b\u5f02\u5e38pod\u7684\u8be6\u7ec6\u4fe1\u606f \u95ee\u9898\u51fa\u73b0 \u4ee5\u4e0a\u53ef\u4ee5\u770b\u5230pod\u5728\u521b\u5efa\u7f16\u53f7\u4e3a9\u7684gpu\u51fa\u73b0\u62a5\u9519\uff0c\u5bfc\u81f4\u8fd9\u6837\u7684\u60c5\u51b5\u53ef\u80fd\u5c31\u662fgpu\u51fa\u95ee\u9898\u4e86 \u63a5\u4e0b\u6765\u53ef\u4ee5\u68c0\u67e5\u8fd9\u4e2apod\u6240\u5728\u7684\u673a\u5668\u4e0a\u7684gpu\uff0c\u770b\u662f\u5426\u51fa\u73b0\u95ee\u9898 \u53ef\u4ee5\u901a\u8fc7 nvidia-smi -L \u547d\u4ee4\u6765\u67e5\u770b \u68c0\u67e5gpu \u51fa\u73b0\u4ee5\u4e0b\u60c5\u51b5\uff0c\u5c1d\u8bd5\u91cd\u542f\u770b\u770b\u662f\u5426\u80fd\u4fee\u590d \u5929\u6d25\u5927\u5b66\u96c6\u7fa4gpu\u786c\u4ef6\u635f\u574f GPU\u635f\u574f \u53ef\u4ee5\u901a\u8fc7nvidia-smi -L \u67e5\u770bgpu\u60c5\u51b5 nvidia-smi Unable to determine the device handle for GPU 0000 :89:00.0: Unknown Error \u611f\u89c9\u662f\u8fd9\u5757\u5361 0000:89:00.0 \u51fa\u95ee\u9898\u4e86\u3002\u7136\u540e\u53bb\u6267\u884c\u4e0b dmesg \u770b\u770b\u60c5\u51b5\uff1a $ dmesg -T [ Mon May 9 20 :37:33 2022 ] xhci_hcd 0000 :89:00.2: PCI post-resume error -19! [ Mon May 9 20 :37:33 2022 ] xhci_hcd 0000 :89:00.2: HC died ; cleaning up [ Mon May 9 20 :37:34 2022 ] nvidia-gpu 0000 :89:00.3: i2c timeout error ffffffff [ Mon May 9 20 :37:34 2022 ] ucsi_ccg 6 -0008: i2c_transfer failed -110 $ nvidia-smi drain -p 0000 :89:00.0 -m 1 Successfully set GPU 00000000 :89:00.0 drain state to: drainin \u5c4f\u853d\u5b8c\u6210\u8fd9\u53f0\u673a\u5668\uff0c\u9700\u8981\u8fdb\u884c\u91cd\u65b0\u542f\u52a8","title":"\u5929\u6d25\u5927\u5b66\u96c6\u7fa4\u95ee\u9898"},{"location":"ubuntu/ubuntu-bmc/","text":"\u8ba4\u8bc6BMC \u00b6 \u57fa\u677f\u7ba1\u7406\u63a7\u5236\u5668 \u652f\u6301IPMI\uff08\u667a\u80fd\u5e73\u53f0\u7ba1\u7406\u63a5\u53e3\uff09 \u7528\u6237\u53ef\u4ee5\u5229\u7528IPMI\u6765\u76d1\u89c6\u670d\u52a1\u5668\u7684\u7269\u7406\u5065\u5eb7\u7279\u5f81\uff0c\u5982\u98ce\u6247\uff0c\u7535\u6e90\uff0c\u5185\u5b58\uff0c\u78c1\u76d8\u7b49 \u597d\u5904\uff1a \u5de5\u7a0b\u5e08\u53ef\u4ee5\u8fdc\u7a0b\u5728\u529e\u516c\u5ba4\u4e2d\u5bf9\u670d\u52a1\u5668\u5f00\u673a \u5173\u673a \u91cd\u88c5\u7cfb\u7edf \u67e5\u770b\u786c\u4ef6\u72b6\u6001 \u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u53bb\u673a\u623f\u7684\u6b21\u6570\uff0c\u6765\u5b8c\u6210\u6211\u4eec\u7684\u6d3b \u5e26\u5916\u7ba1\u7406\u53e3\u89c6\u56fe: \u00b6 \u914d\u7f6eBMC\u5e26\u5916\u7ba1\u7406\u5730\u5740 \u00b6 apt-get install ipmitool ipmitool lan print # \u67e5\u770bBMC\u7684\u5730\u5740 ipmitool lan set 1 ipsrc static ipmitool lan set 1 ipaddr 192 .168.2.21 ipmitool lan set 1 netmask 255 .255.255.0 ipmitool lan set 1 defgw ipaddr 192 .168.2.1 \u8fd9\u6837\u8bbf\u95ee\u8fd9\u4e2a\u5730\u5740\u7684443\u7aef\u53e3\uff0c\u5c31\u53ef\u4ee5\u8bbf\u95ee\u5230\u5e26\u5916\u7ba1\u7406\u4e86\u3002 Mac \u4e0assh\u8f6c\u53d1\u8bbf\u95ee ssh -L 3443:192.168.2.20:443 router2.c1","title":"BMC\u5e26\u5916\u7ba1\u7406"},{"location":"ubuntu/ubuntu-bmc/#bmc","text":"\u57fa\u677f\u7ba1\u7406\u63a7\u5236\u5668 \u652f\u6301IPMI\uff08\u667a\u80fd\u5e73\u53f0\u7ba1\u7406\u63a5\u53e3\uff09 \u7528\u6237\u53ef\u4ee5\u5229\u7528IPMI\u6765\u76d1\u89c6\u670d\u52a1\u5668\u7684\u7269\u7406\u5065\u5eb7\u7279\u5f81\uff0c\u5982\u98ce\u6247\uff0c\u7535\u6e90\uff0c\u5185\u5b58\uff0c\u78c1\u76d8\u7b49 \u597d\u5904\uff1a \u5de5\u7a0b\u5e08\u53ef\u4ee5\u8fdc\u7a0b\u5728\u529e\u516c\u5ba4\u4e2d\u5bf9\u670d\u52a1\u5668\u5f00\u673a \u5173\u673a \u91cd\u88c5\u7cfb\u7edf \u67e5\u770b\u786c\u4ef6\u72b6\u6001 \u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u53bb\u673a\u623f\u7684\u6b21\u6570\uff0c\u6765\u5b8c\u6210\u6211\u4eec\u7684\u6d3b","title":"\u8ba4\u8bc6BMC"},{"location":"ubuntu/ubuntu-bmc/#_1","text":"","title":"\u5e26\u5916\u7ba1\u7406\u53e3\u89c6\u56fe:"},{"location":"ubuntu/ubuntu-bmc/#bmc_1","text":"apt-get install ipmitool ipmitool lan print # \u67e5\u770bBMC\u7684\u5730\u5740 ipmitool lan set 1 ipsrc static ipmitool lan set 1 ipaddr 192 .168.2.21 ipmitool lan set 1 netmask 255 .255.255.0 ipmitool lan set 1 defgw ipaddr 192 .168.2.1 \u8fd9\u6837\u8bbf\u95ee\u8fd9\u4e2a\u5730\u5740\u7684443\u7aef\u53e3\uff0c\u5c31\u53ef\u4ee5\u8bbf\u95ee\u5230\u5e26\u5916\u7ba1\u7406\u4e86\u3002 Mac \u4e0assh\u8f6c\u53d1\u8bbf\u95ee ssh -L 3443:192.168.2.20:443 router2.c1","title":"\u914d\u7f6eBMC\u5e26\u5916\u7ba1\u7406\u5730\u5740"},{"location":"ubuntu/ubuntu-system/","text":"\u7cfb\u7edf\u5b89\u88c5 \u00b6 \u6b63\u6240\u8c13\u4e0d\u4f1a\u88c5\u7cfb\u7edf\u7684\u8fd0\u7ef4\u5c31\u4e0d\u662f\u597d\u8fd0\u7ef4\u7684\u7406\u5ff5\uff0c\u4e0b\u9762\u4ecb\u7ecd\u4e00\u4e0bubuntu\u7cfb\u7edf\u5b89\u88c5 \u51c6\u5907\u5de5\u4f5c \u6b65\u9aa4\u4e00: \u4e0b\u8f7diso\u955c\u50cf \u4e0b\u8f7d\u5730\u5740: https://mirrors.aliyun.com/ubuntu-releases/ \u6b65\u9aa4\u4e8c: \u5236\u4f5c\u7cfb\u7edf\u76d8 \u53ef\u4ee5\u53c2\u8003\u4f7f\u7528\u6280\u5de7\u4e2d\u7684Mac\u5236\u4f5c\u7cfb\u7edf\u76d8\u8fd9\u7bc7\u6587\u7ae0 \u6b65\u9aa4\u4e09: \u88c5\u5c31\u5b8c\u4e8b\u4e86 1.1. \u9009\u62e9\u8bed\u8a00 1.2. \u9009\u62e9\u952e\u76d8\uff08\u672c\u6b65\u9aa4\u76f4\u63a5\u9ed8\u8ba4\u6309\u56de\u8f66\u5373\u53ef\u3002\uff09 1.3. \u914d\u7f6e\u7f51\u7edc\uff08\u4e00\u822c\u60c5\u51b5\u4f1a\u76f4\u63a5\u8df3\u8fc7\u8fd9\u4e00\u6b65\uff09 1.4. \u9009\u62e9\u4ee3\u7406\uff08\u9ed8\u8ba4\u56de\u8f66\u8df3\u8fc7\uff09 1.5. \u914d\u7f6e\u955c\u50cf\u6e90\uff08\u8df3\u8fc7\uff09 1.6. \u9009\u62e9\u78c1\u76d8\uff08\u8fd9\u4e2a\u6b65\u9aa4\u6bd4\u8f83\u5173\u952e\uff09 \u9009\u62e9\u78c1\u76d8\u8fd9\u4e00\u6b65\u9700\u8981\u6ce8\u610f\uff0c\u9700\u8981\u6240\u6709\u78c1\u76d8\u7a7a\u95f4\u5206\u7ed9\u6839\u5206\u533a 1.7. \u7528\u6237\u4fe1\u606f 1.8. openssh server \u5207\u8bb0\u8981\u9009\u62e9\u4e0a ( \u5207\u8bb0 ) \u7cfb\u7edf\u521d\u59cb\u5316 \u00b6 \u521d\u59cb\u5316\u6b65\u9aa4 \u6dfb\u52a0hosts\u4fe1\u606f \u4fee\u6539\u56fd\u5185apt\u6e90 \u6e05\u534e\u6e90 \u963f\u91cc\u6e90 \u6dfb\u52a0\u7ba1\u7406\u5458\u7528\u6237 \u901a\u5e38\u51e0\u4e2a\u7ba1\u7406\u4eba\u5458\u51e0\u4e2a\u7ba1\u7406\u7528\u6237 \u4fee\u6539\u5185\u6838\u53c2\u6570 \u5b89\u88c5\u57fa\u7840\u8f6f\u4ef6\uff0cgpu\u9a71\u52a8 \u5b89\u88c5docker \u5b89\u88c5\u5bb9\u5668\u8fd0\u884c\u65f6 \u5b89\u88c5kubernetes \u5b89\u88c5\u6307\u5b9akubeadm\u7248\u672c \u4ee5\u4e0a\u521d\u59cb\u5316\u53ef\u4ee5\u901a\u8fc7\u8dd1ansible\u6765\u5b9e\u73b0\uff0c\u4e0b\u9762\u5177\u4f53\u62c6\u5206\u6765\u914d\u7f6e\u4e00\u4e0b \u6e29\u99a8\u63d0\u793a \u4ee5\u4e0b\u64cd\u4f5c\u7cfb\u7edf\u7248\u672c\u662f\u4ee5\u6700\u65b0\u7684ubuntu22.04 \u4e3a\u4f8b\u5b50\u6765\u6f14\u793a \u66f4\u6362\u56fd\u5185\u6e90 \u00b6 ubuntu22.04 \u6e05\u534e\u6e90 \u9700\u8981\u6ce8\u610f\u4e00\u4e0b\uff0c\u5982\u679capt update \u62a5\u9519\uff0c\u5c31\u5c06https\u6539\u6210http \u5982\u679c\u9700\u8981\u6dfb\u52a0\u5176\u4ed6\u7684\u7248\u672c\u7684\u6e90\u53ef\u4ee5\u8bbf\u95ee: https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ # \u9ed8\u8ba4\u6ce8\u91ca\u4e86\u6e90\u7801\u955c\u50cf\u4ee5\u63d0\u9ad8 apt update \u901f\u5ea6\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u53d6\u6d88\u6ce8\u91ca deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # \u9884\u53d1\u5e03\u8f6f\u4ef6\u6e90\uff0c\u4e0d\u5efa\u8bae\u542f\u7528 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse \u5b89\u5168 \u00b6 \u4e94: \u7cfb\u7edf\u5b89\u5168 \u00b6 \u901a\u5e38\u5728\u4f01\u4e1a\u4e2d\uff0c\u670d\u52a1\u5668\u4f1a\u906d\u53d7\u5916\u6765\u7684\u5f88\u591a\u7684\u6076\u610f\u653b\u51fb\uff0c\u90a3\u4e48\u670d\u52a1\u5668\u7684\u5b89\u5168\u5c31\u663e\u5f97\u683c\u5916\u7684\u91cd\u8981\u3002\u9996\u5148\u80af\u5b9a\u60f3\u5230\u7684\u662f\u670d\u52a1\u5668\u7684\u5e10\u53f7\u548c\u5bc6\u7801\u7ba1\u7406\uff0c\u901a\u5e38\u7684\u60c5\u51b5\u4e0b\u4f1a\u7981\u6b62root\u8fd9\u6837\u7684\u7ba1\u7406\u5458\u7528\u6237\u767b\u9646\uff0c\u4e5f\u4f1a\u7981\u6b62\u5bc6\u7801\u8fd9\u6837\u7684\u65b9\u5f0f\u767b\u9646\u3002 \u539f\u56e0: root\u7528\u6237\u7684\u6743\u9650\u592a\u9ad8\uff0c\u5982\u679c\u4e00\u65e6\u5e10\u53f7\u5bc6\u7801\u6cc4\u6f0f\uff0c\u5c31\u4f1a\u9020\u6210\u5f88\u4e25\u91cd\u7684\u540e\u679c\u3002 \u7981\u6b62\u5bc6\u7801\u65b9\u5f0f\u767b\u9646\u4e5f\u662f\u4e3a\u4e86\u5b89\u5168\u8003\u8651\uff0c\u6bd5\u7adf\u5bc6\u7801\u4e22\u5931\u4e5f\u662f\u5f88\u5e73\u5e38\u7684\u4e8b\u60c5\u3002\u63a8\u8350\u4f7f\u7528\u516c\u94a5\u7684\u65b9\u5f0f\u6765\u767b\u9646\u670d\u52a1\u5668\u3002 5.1: \u7981\u6b62root\u7528\u6237: \uff08centos/ubuntu\u90fd\u9002\u7528\uff09 \u00b6 \u53ef\u4ee5\u4fee\u6539 /etc/ssh/sshd_config \u914d\u7f6e\u6587\u4ef6 \u6dfb\u52a0: PermitRootLogin yes \u914d\u7f6e\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u5728\u5b8c\u6210\u521d\u59cb\u5316\u5c31\u7981\u6b62root\u767b\u9646\u4e86\uff09 yes \u4e3a\u5141\u8bb8root\u767b\u9646 no \u4e3a\u7981\u6b62root\u767b\u9646 \u91cd\u65b0\u542f\u52a8sshd\u670d\u52a1\u3002 systemctl restart sshd \u5f53\u7136\u4e5f\u53ef\u4ee5\u52a0\u5165\u7cfb\u7edf\u521d\u59cb\u5316\u6b65\u9aa4\u4e2d\uff0c\u7565\uff5e 5.2: \u5bc6\u94a5\u5bf9\u6765\u767b\u9646\u670d\u52a1\u5668 \u00b6 \u751f\u6210\u516c\u94a5\u548c\u79c1\u94a5 root@user:~# ssh-keygen //\u4e00\u8def\u56de\u8f66 Generating public/private rsa key pair. Enter file in which to save the key ( /root/.ssh/id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa Your public key has been saved in /root/.ssh/id_rsa.pub The key fingerprint is: SHA256:J0s/ZHIRTj/UCcDQLHtxd5Qa0p3r2CYlcz7lPS7VaXU root@user The key ' s randomart image is: +--- [ RSA 3072 ] ----+ | . = +.+o.o+ | | .o == .o++. | | ooo+.o.. | | . .. = +E | | S. = X.B | | . X o @+ | | . o * o | | . . . | | . | +---- [ SHA256 ] -----+ \u8fd9\u4e2a\u65f6\u5019\u5728.ssh\u76ee\u5f55\u4e0b\u751f\u6210\u51e0\u4e2a\u6587\u4ef6 root@user:~# ll .ssh/ total 16 drwx------ 2 root root 4096 Sep 20 09 :46 ./ drwx------ 5 root root 4096 Sep 20 09 :35 ../ -rw------- 1 root root 0 May 24 15 :30 authorized_keys // \u8fd9\u4e2a\u662f\u6388\u6743\u6587\u4ef6 -rw------- 1 root root 2590 Sep 20 09 :46 id_rsa // \u8fd9\u4e2a\u662f\u79c1\u94a5\u6587\u4ef6 -rw-r--r-- 1 root root 563 Sep 20 09 :46 id_rsa.pub //\u8fd9\u4e2a\u662f\u516c\u94a5\u6587\u4ef6 \u5c06\u516c\u94a5\u52a0\u5165user\u7528\u6237\u4e0b: .ssh/authorized_keys root@user:/home/user# ls -a .ssh/ . .. authorized_keys root@user:/home/user# cat .ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDwWSc73tyq4TAkXxt3rWmGggbpgdm+egc8mOSDu0hauuvPdieIe1qUbKsIKC1O93KyDPlsfP5gcwqdEmf5Di0S6CCxRh6ENyZ9mtN+s1pCDeHiKbjhPyG4o71tafIDOjhcbpEtCwPA0YTrp5i1oO466qYHeFmTCmkcDFhuEKZx78EZdTwbFH0vhOGTymLFgUVauzmd45ZxpTzaZHrd093nFHWg6FeZWk2axkDiijLALNxiAAaECn2S69y5SxXgKSqpe4Z25b2cKKySlM1lBv1eI7CSxAUoxuXSpcgoRiVUx5VgJwkixKvq8NpihYEkV5pFRjB8W0ssu1YF6d+3MlzOkwa+kir9JJlLq+F/rrBTfF2mCLBgg0KE+voDd8vjEkqSmweNs2gEO7Gi/fUEfcabNAOuNNPL2dhdFl+BH2TCofDYvZcWd8Wrl/0qoW5nbUdCaC7aznb0lpVgseB/gj6ah3adCzfA/W8S+1znD9VMHDdMNy+AN8eeQQ6d2t05SOc = \u8bdd\u4e0d\u591a\u8bf4\u6d4b\u8bd5\u767b\u9646 $ ssh user@172.30.42.244 //\u8fd9\u662f\u6211\u4eec\u4f7f\u7528user\u7528\u6237\u767b\u9646\uff0c\u5c31\u4e0d\u9700\u8981\u5bc6\u7801\u4e86 Welcome to Ubuntu 20 .04.4 LTS ( GNU/Linux 5 .4.0-113-generic x86_64 ) \u7981\u6b62\u7528\u6237\u5bc6\u7801\u767b\u9646 \u4e3a\u4e86\u5b89\u5168\u7684\u8003\u8651\uff0c\u6211\u4eec\u9700\u8981\u5173\u95ed\u7528\u6237\u5bc6\u7801\u767b\u9646\u7684\u8fd9\u79cd\u65b9\u5f0f PubkeyAuthentication yes # \u542f\u7528\u516c\u544a\u5bc6\u94a5\u914d\u5bf9\u8ba4\u8bc1\u65b9\u5f0f RSAAuthentication yes # \u5141\u8bb8RSA\u5bc6\u94a5 PasswordAuthentication no # \u7981\u6b62\u5bc6\u7801\u9a8c\u8bc1\u767b\u5f55,\u5982\u679c\u542f\u7528\u7684\u8bdd,RSA\u8ba4\u8bc1\u767b\u5f55\u5c31\u6ca1\u6709\u610f\u4e49\u4e86 PermitRootLogin no # \u7981\u7528root\u8d26\u6237\u767b\u5f55\uff0c\u975e\u5fc5\u8981\uff0c\u4f46\u4e3a\u4e86\u5b89\u5168\u6027\uff0c\u8bf7\u914d\u7f6e \u8fd9\u6837\u7ed3\u5408\u4e0a\u4e00\u6b65\u9aa4\uff0c\u5173\u95ed\u7528\u6237\u8d26\u53f7\u5bc6\u7801\u9a8c\u8bc1\u65b9\u5f0f\uff0c\u53ea\u91c7\u7528\u5bc6\u94a5\u5bf9\u4f1a\u5b89\u5168\u5f88\u591a\u3002 SSH \u65e0\u6cd5\u767b\u9646 \u53ef\u4ee5ping\u901a\u4f46\u65e0\u6cd5ssh ssh -v ip \u65e0\u660e\u663e\u62a5\u9519 \u8003\u8651\u662f\u5426\u662f\u670d\u52a1\u7aef\u7981\u6b62\u5ba2\u6237\u7aef \u5728/etc/hosts.allow\u6587\u4ef6\u4e2d\u52a0\u4e0a sshd: ALL \uff0c\u91cd\u542fsshd \u4fee\u6539\u7f51\u5361\u914d\u7f6e root@ubuntu:/home/ubuntu# cat /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens18: addresses: - 192.168.1.114/24 gateway4: 192.168.1.1 nameservers: addresses: - 192.168.1.1 search: - 202.106.46.151 version: 2 \u6e05\u9664\u5185\u6838\u7f13\u5b58 https://www.tecmint.com/clear-ram-memory-cache-buffer-and-swap-space-on-linux/ Ubuntu \u7cfb\u7edf\u7ba1\u7406 && \u5b89\u88c5\u53ca\u7ba1\u7406\u7a0b\u5e8f: \u00b6 dpkg \u5305\u5b89\u88c5 \u00b6 \uff081\uff09\u683c\u5f0f \u00b6 dpkg [\u9009\u9879] \u5305\u6587\u4ef6 \uff082\uff09\u7528\u6cd5 \u00b6 \u53c2\u6570 Description - i \u5b89\u88c5 deb \u8f6f\u4ef6\u5305 - r \u5220\u9664 deb \u8f6f\u4ef6\u5305 -r --purge \u8fde\u540c\u914d\u7f6e\u6587\u4ef6\u4e00\u8d77\u5220\u9664 -l \u67e5\u770b\u7cfb\u7edf\u4e2d\u5df2\u5b89\u88c5\u8f6f\u4ef6\u5305\u4fe1\u606f -p \u5378\u8f7d\u8f6f\u4ef6\u5305\u53ca\u5176\u914d\u7f6e\u6587\u4ef6\uff0c\u4f46\u65e0\u6cd5\u89e3\u51b3\u4f9d\u8d56\u5173\u7cfb \uff083\uff09\u8f85\u52a9\u9009\u9879 \u00b6 --force-all \u5f3a\u5236\u5b89\u88c5\u4e00\u4e2a\u5305(\u5ffd\u7565\u4f9d\u8d56\u53ca\u5176\u5b83\u95ee\u9898) apt \u5305\u5b89\u88c5 \u5378\u8f7d \u00b6 \uff081\uff09\u683c\u5f0f \u00b6 apt [options] [command] [package ...] apt \u5728\u7ebf\u5b89\u88c5 \u00b6 // \u8fc7\u6ee4\u51fa\u6765\u4ee5rc\u5f00\u5934\u548cnvidia\u7684\u5305\u5e76\u5378\u8f7d dpkg -l | grep nvidia | grep \"^rc\" | awk '{print $2}' | grep -E 'nvidia' | xargs dpkg --purge dpkg -l | grep nvidia | grep \"^ii\" | awk '{print $2}' | grep -E '^nvidia' | xargs dpkg --force-all -r \u9644\u4ef6: \u00b6 \u6587\u7ae0\u5730\u5740: ubuntu\u5b89\u88c5\u53c2\u8003:","title":"Ubuntu\u64cd\u4f5c\u7cfb\u7edf"},{"location":"ubuntu/ubuntu-system/#_1","text":"\u6b63\u6240\u8c13\u4e0d\u4f1a\u88c5\u7cfb\u7edf\u7684\u8fd0\u7ef4\u5c31\u4e0d\u662f\u597d\u8fd0\u7ef4\u7684\u7406\u5ff5\uff0c\u4e0b\u9762\u4ecb\u7ecd\u4e00\u4e0bubuntu\u7cfb\u7edf\u5b89\u88c5 \u51c6\u5907\u5de5\u4f5c \u6b65\u9aa4\u4e00: \u4e0b\u8f7diso\u955c\u50cf \u4e0b\u8f7d\u5730\u5740: https://mirrors.aliyun.com/ubuntu-releases/ \u6b65\u9aa4\u4e8c: \u5236\u4f5c\u7cfb\u7edf\u76d8 \u53ef\u4ee5\u53c2\u8003\u4f7f\u7528\u6280\u5de7\u4e2d\u7684Mac\u5236\u4f5c\u7cfb\u7edf\u76d8\u8fd9\u7bc7\u6587\u7ae0 \u6b65\u9aa4\u4e09: \u88c5\u5c31\u5b8c\u4e8b\u4e86 1.1. \u9009\u62e9\u8bed\u8a00 1.2. \u9009\u62e9\u952e\u76d8\uff08\u672c\u6b65\u9aa4\u76f4\u63a5\u9ed8\u8ba4\u6309\u56de\u8f66\u5373\u53ef\u3002\uff09 1.3. \u914d\u7f6e\u7f51\u7edc\uff08\u4e00\u822c\u60c5\u51b5\u4f1a\u76f4\u63a5\u8df3\u8fc7\u8fd9\u4e00\u6b65\uff09 1.4. \u9009\u62e9\u4ee3\u7406\uff08\u9ed8\u8ba4\u56de\u8f66\u8df3\u8fc7\uff09 1.5. \u914d\u7f6e\u955c\u50cf\u6e90\uff08\u8df3\u8fc7\uff09 1.6. \u9009\u62e9\u78c1\u76d8\uff08\u8fd9\u4e2a\u6b65\u9aa4\u6bd4\u8f83\u5173\u952e\uff09 \u9009\u62e9\u78c1\u76d8\u8fd9\u4e00\u6b65\u9700\u8981\u6ce8\u610f\uff0c\u9700\u8981\u6240\u6709\u78c1\u76d8\u7a7a\u95f4\u5206\u7ed9\u6839\u5206\u533a 1.7. \u7528\u6237\u4fe1\u606f 1.8. openssh server \u5207\u8bb0\u8981\u9009\u62e9\u4e0a ( \u5207\u8bb0 )","title":"\u7cfb\u7edf\u5b89\u88c5"},{"location":"ubuntu/ubuntu-system/#_2","text":"\u521d\u59cb\u5316\u6b65\u9aa4 \u6dfb\u52a0hosts\u4fe1\u606f \u4fee\u6539\u56fd\u5185apt\u6e90 \u6e05\u534e\u6e90 \u963f\u91cc\u6e90 \u6dfb\u52a0\u7ba1\u7406\u5458\u7528\u6237 \u901a\u5e38\u51e0\u4e2a\u7ba1\u7406\u4eba\u5458\u51e0\u4e2a\u7ba1\u7406\u7528\u6237 \u4fee\u6539\u5185\u6838\u53c2\u6570 \u5b89\u88c5\u57fa\u7840\u8f6f\u4ef6\uff0cgpu\u9a71\u52a8 \u5b89\u88c5docker \u5b89\u88c5\u5bb9\u5668\u8fd0\u884c\u65f6 \u5b89\u88c5kubernetes \u5b89\u88c5\u6307\u5b9akubeadm\u7248\u672c \u4ee5\u4e0a\u521d\u59cb\u5316\u53ef\u4ee5\u901a\u8fc7\u8dd1ansible\u6765\u5b9e\u73b0\uff0c\u4e0b\u9762\u5177\u4f53\u62c6\u5206\u6765\u914d\u7f6e\u4e00\u4e0b \u6e29\u99a8\u63d0\u793a \u4ee5\u4e0b\u64cd\u4f5c\u7cfb\u7edf\u7248\u672c\u662f\u4ee5\u6700\u65b0\u7684ubuntu22.04 \u4e3a\u4f8b\u5b50\u6765\u6f14\u793a","title":"\u7cfb\u7edf\u521d\u59cb\u5316"},{"location":"ubuntu/ubuntu-system/#_3","text":"ubuntu22.04 \u6e05\u534e\u6e90 \u9700\u8981\u6ce8\u610f\u4e00\u4e0b\uff0c\u5982\u679capt update \u62a5\u9519\uff0c\u5c31\u5c06https\u6539\u6210http \u5982\u679c\u9700\u8981\u6dfb\u52a0\u5176\u4ed6\u7684\u7248\u672c\u7684\u6e90\u53ef\u4ee5\u8bbf\u95ee: https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ # \u9ed8\u8ba4\u6ce8\u91ca\u4e86\u6e90\u7801\u955c\u50cf\u4ee5\u63d0\u9ad8 apt update \u901f\u5ea6\uff0c\u5982\u6709\u9700\u8981\u53ef\u81ea\u884c\u53d6\u6d88\u6ce8\u91ca deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # \u9884\u53d1\u5e03\u8f6f\u4ef6\u6e90\uff0c\u4e0d\u5efa\u8bae\u542f\u7528 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse","title":"\u66f4\u6362\u56fd\u5185\u6e90"},{"location":"ubuntu/ubuntu-system/#_4","text":"","title":"\u5b89\u5168"},{"location":"ubuntu/ubuntu-system/#_5","text":"\u901a\u5e38\u5728\u4f01\u4e1a\u4e2d\uff0c\u670d\u52a1\u5668\u4f1a\u906d\u53d7\u5916\u6765\u7684\u5f88\u591a\u7684\u6076\u610f\u653b\u51fb\uff0c\u90a3\u4e48\u670d\u52a1\u5668\u7684\u5b89\u5168\u5c31\u663e\u5f97\u683c\u5916\u7684\u91cd\u8981\u3002\u9996\u5148\u80af\u5b9a\u60f3\u5230\u7684\u662f\u670d\u52a1\u5668\u7684\u5e10\u53f7\u548c\u5bc6\u7801\u7ba1\u7406\uff0c\u901a\u5e38\u7684\u60c5\u51b5\u4e0b\u4f1a\u7981\u6b62root\u8fd9\u6837\u7684\u7ba1\u7406\u5458\u7528\u6237\u767b\u9646\uff0c\u4e5f\u4f1a\u7981\u6b62\u5bc6\u7801\u8fd9\u6837\u7684\u65b9\u5f0f\u767b\u9646\u3002 \u539f\u56e0: root\u7528\u6237\u7684\u6743\u9650\u592a\u9ad8\uff0c\u5982\u679c\u4e00\u65e6\u5e10\u53f7\u5bc6\u7801\u6cc4\u6f0f\uff0c\u5c31\u4f1a\u9020\u6210\u5f88\u4e25\u91cd\u7684\u540e\u679c\u3002 \u7981\u6b62\u5bc6\u7801\u65b9\u5f0f\u767b\u9646\u4e5f\u662f\u4e3a\u4e86\u5b89\u5168\u8003\u8651\uff0c\u6bd5\u7adf\u5bc6\u7801\u4e22\u5931\u4e5f\u662f\u5f88\u5e73\u5e38\u7684\u4e8b\u60c5\u3002\u63a8\u8350\u4f7f\u7528\u516c\u94a5\u7684\u65b9\u5f0f\u6765\u767b\u9646\u670d\u52a1\u5668\u3002","title":"\u4e94: \u7cfb\u7edf\u5b89\u5168"},{"location":"ubuntu/ubuntu-system/#51-root-centosubuntu","text":"\u53ef\u4ee5\u4fee\u6539 /etc/ssh/sshd_config \u914d\u7f6e\u6587\u4ef6 \u6dfb\u52a0: PermitRootLogin yes \u914d\u7f6e\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u5728\u5b8c\u6210\u521d\u59cb\u5316\u5c31\u7981\u6b62root\u767b\u9646\u4e86\uff09 yes \u4e3a\u5141\u8bb8root\u767b\u9646 no \u4e3a\u7981\u6b62root\u767b\u9646 \u91cd\u65b0\u542f\u52a8sshd\u670d\u52a1\u3002 systemctl restart sshd \u5f53\u7136\u4e5f\u53ef\u4ee5\u52a0\u5165\u7cfb\u7edf\u521d\u59cb\u5316\u6b65\u9aa4\u4e2d\uff0c\u7565\uff5e","title":"5.1: \u7981\u6b62root\u7528\u6237: \uff08centos/ubuntu\u90fd\u9002\u7528\uff09"},{"location":"ubuntu/ubuntu-system/#52","text":"\u751f\u6210\u516c\u94a5\u548c\u79c1\u94a5 root@user:~# ssh-keygen //\u4e00\u8def\u56de\u8f66 Generating public/private rsa key pair. Enter file in which to save the key ( /root/.ssh/id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa Your public key has been saved in /root/.ssh/id_rsa.pub The key fingerprint is: SHA256:J0s/ZHIRTj/UCcDQLHtxd5Qa0p3r2CYlcz7lPS7VaXU root@user The key ' s randomart image is: +--- [ RSA 3072 ] ----+ | . = +.+o.o+ | | .o == .o++. | | ooo+.o.. | | . .. = +E | | S. = X.B | | . X o @+ | | . o * o | | . . . | | . | +---- [ SHA256 ] -----+ \u8fd9\u4e2a\u65f6\u5019\u5728.ssh\u76ee\u5f55\u4e0b\u751f\u6210\u51e0\u4e2a\u6587\u4ef6 root@user:~# ll .ssh/ total 16 drwx------ 2 root root 4096 Sep 20 09 :46 ./ drwx------ 5 root root 4096 Sep 20 09 :35 ../ -rw------- 1 root root 0 May 24 15 :30 authorized_keys // \u8fd9\u4e2a\u662f\u6388\u6743\u6587\u4ef6 -rw------- 1 root root 2590 Sep 20 09 :46 id_rsa // \u8fd9\u4e2a\u662f\u79c1\u94a5\u6587\u4ef6 -rw-r--r-- 1 root root 563 Sep 20 09 :46 id_rsa.pub //\u8fd9\u4e2a\u662f\u516c\u94a5\u6587\u4ef6 \u5c06\u516c\u94a5\u52a0\u5165user\u7528\u6237\u4e0b: .ssh/authorized_keys root@user:/home/user# ls -a .ssh/ . .. authorized_keys root@user:/home/user# cat .ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDwWSc73tyq4TAkXxt3rWmGggbpgdm+egc8mOSDu0hauuvPdieIe1qUbKsIKC1O93KyDPlsfP5gcwqdEmf5Di0S6CCxRh6ENyZ9mtN+s1pCDeHiKbjhPyG4o71tafIDOjhcbpEtCwPA0YTrp5i1oO466qYHeFmTCmkcDFhuEKZx78EZdTwbFH0vhOGTymLFgUVauzmd45ZxpTzaZHrd093nFHWg6FeZWk2axkDiijLALNxiAAaECn2S69y5SxXgKSqpe4Z25b2cKKySlM1lBv1eI7CSxAUoxuXSpcgoRiVUx5VgJwkixKvq8NpihYEkV5pFRjB8W0ssu1YF6d+3MlzOkwa+kir9JJlLq+F/rrBTfF2mCLBgg0KE+voDd8vjEkqSmweNs2gEO7Gi/fUEfcabNAOuNNPL2dhdFl+BH2TCofDYvZcWd8Wrl/0qoW5nbUdCaC7aznb0lpVgseB/gj6ah3adCzfA/W8S+1znD9VMHDdMNy+AN8eeQQ6d2t05SOc = \u8bdd\u4e0d\u591a\u8bf4\u6d4b\u8bd5\u767b\u9646 $ ssh user@172.30.42.244 //\u8fd9\u662f\u6211\u4eec\u4f7f\u7528user\u7528\u6237\u767b\u9646\uff0c\u5c31\u4e0d\u9700\u8981\u5bc6\u7801\u4e86 Welcome to Ubuntu 20 .04.4 LTS ( GNU/Linux 5 .4.0-113-generic x86_64 ) \u7981\u6b62\u7528\u6237\u5bc6\u7801\u767b\u9646 \u4e3a\u4e86\u5b89\u5168\u7684\u8003\u8651\uff0c\u6211\u4eec\u9700\u8981\u5173\u95ed\u7528\u6237\u5bc6\u7801\u767b\u9646\u7684\u8fd9\u79cd\u65b9\u5f0f PubkeyAuthentication yes # \u542f\u7528\u516c\u544a\u5bc6\u94a5\u914d\u5bf9\u8ba4\u8bc1\u65b9\u5f0f RSAAuthentication yes # \u5141\u8bb8RSA\u5bc6\u94a5 PasswordAuthentication no # \u7981\u6b62\u5bc6\u7801\u9a8c\u8bc1\u767b\u5f55,\u5982\u679c\u542f\u7528\u7684\u8bdd,RSA\u8ba4\u8bc1\u767b\u5f55\u5c31\u6ca1\u6709\u610f\u4e49\u4e86 PermitRootLogin no # \u7981\u7528root\u8d26\u6237\u767b\u5f55\uff0c\u975e\u5fc5\u8981\uff0c\u4f46\u4e3a\u4e86\u5b89\u5168\u6027\uff0c\u8bf7\u914d\u7f6e \u8fd9\u6837\u7ed3\u5408\u4e0a\u4e00\u6b65\u9aa4\uff0c\u5173\u95ed\u7528\u6237\u8d26\u53f7\u5bc6\u7801\u9a8c\u8bc1\u65b9\u5f0f\uff0c\u53ea\u91c7\u7528\u5bc6\u94a5\u5bf9\u4f1a\u5b89\u5168\u5f88\u591a\u3002 SSH \u65e0\u6cd5\u767b\u9646 \u53ef\u4ee5ping\u901a\u4f46\u65e0\u6cd5ssh ssh -v ip \u65e0\u660e\u663e\u62a5\u9519 \u8003\u8651\u662f\u5426\u662f\u670d\u52a1\u7aef\u7981\u6b62\u5ba2\u6237\u7aef \u5728/etc/hosts.allow\u6587\u4ef6\u4e2d\u52a0\u4e0a sshd: ALL \uff0c\u91cd\u542fsshd \u4fee\u6539\u7f51\u5361\u914d\u7f6e root@ubuntu:/home/ubuntu# cat /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens18: addresses: - 192.168.1.114/24 gateway4: 192.168.1.1 nameservers: addresses: - 192.168.1.1 search: - 202.106.46.151 version: 2 \u6e05\u9664\u5185\u6838\u7f13\u5b58 https://www.tecmint.com/clear-ram-memory-cache-buffer-and-swap-space-on-linux/","title":"5.2: \u5bc6\u94a5\u5bf9\u6765\u767b\u9646\u670d\u52a1\u5668"},{"location":"ubuntu/ubuntu-system/#ubuntu","text":"","title":"Ubuntu \u7cfb\u7edf\u7ba1\u7406 &amp;&amp; \u5b89\u88c5\u53ca\u7ba1\u7406\u7a0b\u5e8f:"},{"location":"ubuntu/ubuntu-system/#dpkg","text":"","title":"dpkg \u5305\u5b89\u88c5"},{"location":"ubuntu/ubuntu-system/#1","text":"dpkg [\u9009\u9879] \u5305\u6587\u4ef6","title":"\uff081\uff09\u683c\u5f0f"},{"location":"ubuntu/ubuntu-system/#2","text":"\u53c2\u6570 Description - i \u5b89\u88c5 deb \u8f6f\u4ef6\u5305 - r \u5220\u9664 deb \u8f6f\u4ef6\u5305 -r --purge \u8fde\u540c\u914d\u7f6e\u6587\u4ef6\u4e00\u8d77\u5220\u9664 -l \u67e5\u770b\u7cfb\u7edf\u4e2d\u5df2\u5b89\u88c5\u8f6f\u4ef6\u5305\u4fe1\u606f -p \u5378\u8f7d\u8f6f\u4ef6\u5305\u53ca\u5176\u914d\u7f6e\u6587\u4ef6\uff0c\u4f46\u65e0\u6cd5\u89e3\u51b3\u4f9d\u8d56\u5173\u7cfb","title":"\uff082\uff09\u7528\u6cd5"},{"location":"ubuntu/ubuntu-system/#3","text":"--force-all \u5f3a\u5236\u5b89\u88c5\u4e00\u4e2a\u5305(\u5ffd\u7565\u4f9d\u8d56\u53ca\u5176\u5b83\u95ee\u9898)","title":"\uff083\uff09\u8f85\u52a9\u9009\u9879"},{"location":"ubuntu/ubuntu-system/#apt","text":"","title":"apt \u5305\u5b89\u88c5 \u5378\u8f7d"},{"location":"ubuntu/ubuntu-system/#1_1","text":"apt [options] [command] [package ...]","title":"\uff081\uff09\u683c\u5f0f"},{"location":"ubuntu/ubuntu-system/#apt_1","text":"// \u8fc7\u6ee4\u51fa\u6765\u4ee5rc\u5f00\u5934\u548cnvidia\u7684\u5305\u5e76\u5378\u8f7d dpkg -l | grep nvidia | grep \"^rc\" | awk '{print $2}' | grep -E 'nvidia' | xargs dpkg --purge dpkg -l | grep nvidia | grep \"^ii\" | awk '{print $2}' | grep -E '^nvidia' | xargs dpkg --force-all -r","title":"apt \u5728\u7ebf\u5b89\u88c5"},{"location":"ubuntu/ubuntu-system/#_6","text":"\u6587\u7ae0\u5730\u5740: ubuntu\u5b89\u88c5\u53c2\u8003:","title":"\u9644\u4ef6:"}]}